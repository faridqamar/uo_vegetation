{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering of Hyperspectral Vegetation \n",
    "\n",
    "### standardized spectra at full resolution without spatial dimension\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- here are functions that generate a class that memory maps the raw data \n",
    "#    cube.  After executing this cell, the syntax is:\n",
    "#    fname = \"[path to data]/foo.raw\"\n",
    "#    cube = read_hyper(fname)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def read_header(hdrfile, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a Middleton header file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hdrfile : str\n",
    "        Name of header file.\n",
    "    verbose : bool, optional\n",
    "        If True, alert the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : dict\n",
    "        A dictionary continaing the number of rows, columns, and wavelengths\n",
    "        as well as an array of band centers.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- alert\n",
    "    if verbose:\n",
    "        print(\"reading and parsing {0}...\".format(hdrfile))\n",
    "\n",
    "    # -- open the file and read in the records\n",
    "    recs = [rec for rec in open(hdrfile)]\n",
    "\n",
    "    # -- parse for samples, lines, bands, and the start of the wavelengths\n",
    "    for irec, rec in enumerate(recs):\n",
    "        if 'samples' in rec:\n",
    "            samples = int(rec.split(\"=\")[1])\n",
    "        elif 'lines' in rec:\n",
    "            lines = int(rec.split(\"=\")[1])\n",
    "        elif 'bands' in rec:\n",
    "            bands = int(rec.split(\"=\")[1])\n",
    "        elif \"Wavelength\" in rec:\n",
    "            w0ind = irec+1\n",
    "\n",
    "    # -- parse for the wavelengths\n",
    "    waves = np.array([float(rec.split(\",\")[0]) for rec in \n",
    "                      recs[w0ind:w0ind+bands]])\n",
    "\n",
    "    # -- return a dictionary\n",
    "    return {\"nrow\":samples, \"ncol\":lines, \"nwav\":bands, \"waves\":waves}\n",
    "\n",
    "\n",
    "def read_raw(rawfile, shape, hyper=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a Middleton raw file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rawfile : str\n",
    "        The name of the raw file.\n",
    "    shape : tuple\n",
    "        The output shape of the data cube (nwav, nrow, ncol).\n",
    "    hyper : bool, optional\n",
    "        Set this flag to read a hyperspectral image.\n",
    "    verbose : bool, optional\n",
    "        Alert the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    memmap : memmap\n",
    "        A numpy memmap of the datacube.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- alert\n",
    "    if verbose:\n",
    "        print(\"reading {0}...\".format(rawfile))\n",
    "\n",
    "    # -- read either broadband or hyperspectral image\n",
    "    if hyper:\n",
    "        return np.memmap(rawfile, np.uint16, mode=\"r\") \\\n",
    "            .reshape(shape[2], shape[0], shape[1])[:, :, ::-1] \\\n",
    "            .transpose(1, 2, 0)\n",
    "    else:\n",
    "        return np.memmap(rawfile, np.uint8, mode=\"r\") \\\n",
    "            .reshape(shape[1], shape[2], shape[0])[:, :, ::-1]\n",
    "\n",
    "\n",
    "def read_hyper(fpath, fname=None, full=True):\n",
    "    \"\"\"\n",
    "    Read a full hyperspectral scan (raw and header file).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fpath : str\n",
    "        Either the full name+path of the raw file or the path of the raw file.\n",
    "        If the latter, fname must be supplied.\n",
    "    fname : str, optional\n",
    "        The name of the raw file (required if fpath is set to a path).\n",
    "    full : bool, optional\n",
    "        If True, output a class containing data and supplementary information.\n",
    "        If False, output only the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output or memmap : class or memmap\n",
    "        If full is True, a class containing data plus supplementary \n",
    "        information.  If full is False, a memmap array of the data.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- set up the file names\n",
    "    if fname is not None:\n",
    "        fpath = os.path.join(fpath, fname)\n",
    "\n",
    "    # -- read the header\n",
    "    hdr = read_header(fpath.replace(\"raw\", \"hdr\"))\n",
    "    sh  = (hdr[\"nwav\"], hdr[\"nrow\"], hdr[\"ncol\"])\n",
    "\n",
    "    # -- if desired, only output data cube\n",
    "    if not full:\n",
    "        return read_raw(fpath, sh, hyper=True)\n",
    "\n",
    "    # -- output full structure\n",
    "    class output():\n",
    "        def __init__(self, fpath):\n",
    "            self.filename = fpath\n",
    "            self.data     = read_raw(fpath, sh, hyper=True)\n",
    "            self.waves    = hdr[\"waves\"]\n",
    "            self.nwav     = sh[0]\n",
    "            self.nrow     = sh[1]\n",
    "            self.ncol     = sh[2]\n",
    "\n",
    "    return output(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_test_dictionary(labels, test, k):\n",
    "    import collections, numpy\n",
    "    \n",
    "    unique_test, counts_test = numpy.unique(labels[test[:,0], test[:,1]], return_counts=True)\n",
    "    counts_test_norm = (counts_test/test.shape[0])*100\n",
    "    test_dict = dict(zip(unique_test, counts_test))\n",
    "    test_dict_norm = dict(zip(unique_test, counts_test_norm))\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        if test_dict.get(i) is None: test_dict[i] = 0\n",
    "        if test_dict_norm.get(i) is None: test_dict_norm[i] = 0\n",
    "    \n",
    "    return test_dict, test_dict_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_test_dataframe(sky_dict,\n",
    "                          clouds_dict,\n",
    "                          veg_dict,\n",
    "                          wtr_dict,\n",
    "                          blt_dict,\n",
    "                          windows_dict,\n",
    "                          rds_dict,\n",
    "                          cars_dict,\n",
    "                          mtl_dict\n",
    "                         ):\n",
    "    import pandas as pd\n",
    "    \n",
    "    pixel_names = ['sky', 'clouds', 'vegetation', 'water', 'built',\n",
    "                  'windows', 'roads', 'cars', 'metal']\n",
    "    df_test = pd.DataFrame([sky_dict,\n",
    "                            clouds_dict,\n",
    "                            veg_dict,\n",
    "                            wtr_dict,\n",
    "                            blt_dict,\n",
    "                            windows_dict,\n",
    "                            rds_dict,\n",
    "                            cars_dict,\n",
    "                            mtl_dict], index=pixel_names)\n",
    "    df_test = df_test.transpose()\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(df_test, norm=True):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    cm = np.array([df_test['sky'].values,\n",
    "                   df_test['clouds'].values,\n",
    "                   df_test['vegetation'].values,\n",
    "                   df_test['water'].values,\n",
    "                   df_test['built'].values,\n",
    "                   df_test['windows'].values,\n",
    "                   df_test['roads'].values,\n",
    "                   df_test['cars'].values,\n",
    "                   df_test['metal'].values])\n",
    "    classes = ['sky', 'clouds', 'vegetation', 'water', 'built', 'windows', 'roads', \n",
    "              'cars', 'metal']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    if norm:\n",
    "        title='Normalized Confusion Matrix'\n",
    "        fmt='.2f'\n",
    "    else:\n",
    "        title='Confusion Matrix'\n",
    "        fmt='d'\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "          yticks=np.arange(cm.shape[0]),\n",
    "          xticklabels=np.arange(0,cm.shape[1]).astype(str), \n",
    "          yticklabels=classes,\n",
    "          title=title,\n",
    "          ylabel='True Label',\n",
    "          xlabel='Predicted Label')\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "    #        rotation_mode=\"anchor\")\n",
    "    thresh = cm.max()/2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i,j], fmt),\n",
    "                   ha=\"center\", va=\"center\",\n",
    "                   color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_result(df_Test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    df_test = df_Test.transpose()\n",
    "    ax = df_test.plot.bar(rot=0, stacked=True, colormap='tab20b')\n",
    "                          #color=['tab:blue', 'tab:green', 'tab:gray'])\n",
    "    plt.xlabel('Actual Class')\n",
    "    plt.ylabel('%of Test Pixels')\n",
    "    plt.title('Error in Kmeans Prediction')\n",
    "    plt.legend(bbox_to_anchor=(1,1), loc=2, borderaxespad=1.0, prop={'size':11})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_from_string(text):\n",
    "    \n",
    "    items = text.strip(\"\\n\").split(\" \")\n",
    "    rind = int(items[0])\n",
    "    cind = int(items[1])\n",
    "    \n",
    "    return rind, cind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords(row, col):\n",
    "    return np.array(list(np.ndindex((row, col)))).reshape(row, col, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Goal of clustering:\n",
    "1. Sky\n",
    "2. Clouds\n",
    "3. Water\n",
    "4. Vegetation\n",
    "5. Buildings (concrete structures)\n",
    "6. Windows\n",
    "7. Roads\n",
    "8. Cars\n",
    "9. Metal Structures\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans on veg_00108 (South Facing @ ~2pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and parsing ../../../image_files/veg_00108.hdr...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../image_files/veg_00108.hdr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-885fc011a79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../../image_files/veg_00108.raw\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcube\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-d26b4959d706>\u001b[0m in \u001b[0;36mread_hyper\u001b[0;34m(fpath, fname, full)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# -- read the header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mhdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hdr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0msh\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nwav\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nrow\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ncol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d26b4959d706>\u001b[0m in \u001b[0;36mread_header\u001b[0;34m(hdrfile, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# -- open the file and read in the records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrec\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdrfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# -- parse for samples, lines, bands, and the start of the wavelengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../image_files/veg_00108.hdr'"
     ]
    }
   ],
   "source": [
    "fname = \"../../image_files/veg_00108.raw\"\n",
    "cube = read_hyper(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_sub = cube.data[:, :, :].astype(float)\n",
    "print(cube_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_reshaped = cube_sub.transpose(1, 2, 0).reshape((cube_sub.shape[1] * cube_sub.shape[2]), cube_sub.shape[0])\n",
    "print(cube_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_standard = (cube_reshaped - cube_reshaped.mean(1, keepdims=True)) / cube_reshaped.std(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_norm = (cube_reshaped - cube_reshaped.min()) / (cube_reshaped.max() - cube_reshaped.min())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "red_ind = (np.abs(cube.waves - 650.0)).argmin()\n",
    "green_ind = (np.abs(cube.waves - 550.0)).argmin()\n",
    "blue_ind = (np.abs(cube.waves - 450.0)).argmin()\n",
    "\n",
    "cube_reshaped2 = cube_norm.reshape(cube_sub.shape[1], cube_sub.shape[2], cube_sub.shape[0])\n",
    "cube_scene = cube_reshaped2[:, :, [red_ind, green_ind, blue_ind]]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('veg_00108 RGB Image')\n",
    "ax.imshow(cube_scene, aspect=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cube_reshaped2[:, :, [red_ind, green_ind, blue_ind]].copy()\n",
    "rgb /= rgb.mean((0, 1), keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('veg_00108 corrected RGB Image')\n",
    "ax.imshow(rgb, aspect=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create position array and normalize\n",
    "\n",
    "xycoords = coords(cube_sub.shape[1], cube_sub.shape[2])\n",
    "xycoords = xycoords/xycoords.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append row, col position matrix to spectral data\n",
    "\n",
    "cube_temp = cube_standard.reshape(cube_sub.shape[1], cube_sub.shape[2], cube_sub.shape[0])\n",
    "cube_specxy = np.append(cube_temp, xycoords, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape spectral and spatial cube for clustering\n",
    "cube_specxy_2d = cube_specxy.reshape((cube_specxy.shape[0] * cube_specxy.shape[1]), cube_specxy.shape[2])\n",
    "print(cube_specxy_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "km = MiniBatchKMeans(n_clusters=9, random_state=2, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "kmeans = km.fit(cube_specxy_2d)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize=(12, 12))\n",
    "plt.suptitle('Standardized Spectra of Kmeans Cluster Centers (veg_00108)')\n",
    "ax1.plot(cube.waves, kmeans.cluster_centers_[0,:-2], color=[0.0,0.33,0.62])\n",
    "ax2.plot(cube.waves, kmeans.cluster_centers_[1,:-2], color=[0.0,0.33,0.62])\n",
    "ax3.plot(cube.waves, kmeans.cluster_centers_[2,:-2], color=[0.0,0.33,0.62])\n",
    "ax4.plot(cube.waves, kmeans.cluster_centers_[3,:-2], color=[0.0,0.33,0.62])\n",
    "ax5.plot(cube.waves, kmeans.cluster_centers_[4,:-2], color=[0.0,0.33,0.62])\n",
    "ax6.plot(cube.waves, kmeans.cluster_centers_[5,:-2], color=[0.0,0.33,0.62])\n",
    "ax7.plot(cube.waves, kmeans.cluster_centers_[6,:-2], color=[0.0,0.33,0.62])\n",
    "ax8.plot(cube.waves, kmeans.cluster_centers_[7,:-2], color=[0.0,0.33,0.62])\n",
    "ax9.plot(cube.waves, kmeans.cluster_centers_[8,:-2], color=[0.0,0.33,0.62])\n",
    "plt.show()\n",
    "#f.savefig(\"./output/plots/13_kmeans_cluster_centers_spectra_standardized_4_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.predict(cube_specxy_2d)\n",
    "labels_reshape = labels.reshape(cube_sub.shape[1], cube_sub.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Paired9\n",
    "from bokeh.models import (ColorBar, LinearColorMapper)\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "labels_reverse = np.flip(labels_reshape, axis=0)\n",
    "color_mapper = LinearColorMapper(palette=\"Paired9\", low=labels_reverse.min(), \n",
    "                                 high=labels_reverse.max())\n",
    "\n",
    "source_data = dict(image=[labels_reverse],\n",
    "                  x=[0],\n",
    "                  y=[0],\n",
    "                  dw=[1600],\n",
    "                  dh=[1600])\n",
    "\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [\n",
    "    (\"Label\", \"@image\"),\n",
    "    (\"x\", \"@x\"),\n",
    "    (\"y\", \"@y\"),\n",
    "]\n",
    "\n",
    "output_notebook()\n",
    "imgplt = figure(plot_width=800, plot_height=400, x_range=(0,1600), y_range=(0,1600),\n",
    "               tools=['pan','tap','box_zoom','wheel_zoom','save','reset'],\n",
    "               title=\"Clustered Standardized Spectra (veg_00108)\")\n",
    "imgplt.image(source=source_data, image='image', x='x', y='y', dw='dw', dh='dh',\n",
    "            color_mapper = color_mapper)\n",
    "imgplt.add_layout(ColorBar(color_mapper = color_mapper), 'left')\n",
    "imgplt.tools.append(hover)\n",
    "show(imgplt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read test sample (veg_00108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read manually selected coordinates files\n",
    "\n",
    "#sky coordinates\n",
    "sky_file = open(\"../../manual_classified_pixels/1_sky_coordinates_108.txt\", \"r\")\n",
    "sky_coords = sky_file.readlines()\n",
    "sky_file.close()\n",
    "sky_coords = np.array([point_from_string(line) for line in sky_coords])\n",
    "print(\"sky:        \", sky_coords.shape)\n",
    "\n",
    "#clouds coordinates\n",
    "clouds_file = open(\"../../manual_classified_pixels/2_clouds_coordinates_108.txt\", \"r\")\n",
    "clouds_coords = clouds_file.readlines()\n",
    "clouds_file.close()\n",
    "clouds_coords = np.array([point_from_string(line) for line in clouds_coords])\n",
    "print(\"clouds:     \", clouds_coords.shape)\n",
    "\n",
    "#vegetation coordinates\n",
    "veg_file = open(\"../../manual_classified_pixels/3_vegetation_coordinates_108.txt\", \"r\")\n",
    "veg_coords = veg_file.readlines()\n",
    "veg_file.close()\n",
    "veg_coords = np.array([point_from_string(line) for line in veg_coords])\n",
    "print(\"vegetation: \", veg_coords.shape)\n",
    "\n",
    "#water coordinates\n",
    "wtr_file = open(\"../../manual_classified_pixels/4_water_coordinates_108.txt\", \"r\")\n",
    "wtr_coords = wtr_file.readlines()\n",
    "wtr_file.close()\n",
    "wtr_coords = np.array([point_from_string(line) for line in wtr_coords])\n",
    "print(\"water:      \", wtr_coords.shape)\n",
    "\n",
    "#buildings coordinates\n",
    "blt_file = open(\"../../manual_classified_pixels/5_buildings_coordinates_108.txt\", \"r\")\n",
    "blt_coords = blt_file.readlines()\n",
    "blt_file.close()\n",
    "blt_coords = np.array([point_from_string(line) for line in blt_coords])\n",
    "print(\"buildings:  \", blt_coords.shape)\n",
    "\n",
    "#windows coordinates\n",
    "windows_file = open(\"../../manual_classified_pixels/6_windows_coordinates_108.txt\", \"r\")\n",
    "windows_coords = windows_file.readlines()\n",
    "windows_file.close()\n",
    "windows_coords = np.array([point_from_string(line) for line in windows_coords])\n",
    "print(\"windows:    \", windows_coords.shape)\n",
    "\n",
    "#roads coordinates\n",
    "rds_file = open(\"../../manual_classified_pixels/7_roads_coordinates_108.txt\", \"r\")\n",
    "rds_coords = rds_file.readlines()\n",
    "rds_file.close()\n",
    "rds_coords = np.array([point_from_string(line) for line in rds_coords])\n",
    "print(\"road:       \", rds_coords.shape)\n",
    "\n",
    "#cars coordinates\n",
    "cars_file = open(\"../../manual_classified_pixels/8_cars_coordinates_108.txt\", \"r\")\n",
    "cars_coords = cars_file.readlines()\n",
    "cars_file.close()\n",
    "cars_coords = np.array([point_from_string(line) for line in cars_coords])\n",
    "print(\"cars:       \", cars_coords.shape)\n",
    "\n",
    "#metal coordinates\n",
    "mtl_file = open(\"../../manual_classified_pixels/9_metal_coordinates_108.txt\", \"r\")\n",
    "mtl_coords = mtl_file.readlines()\n",
    "mtl_file.close()\n",
    "mtl_coords = np.array([point_from_string(line) for line in mtl_coords])\n",
    "print(\"metal:      \", mtl_coords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred_sky = labels_reshape[sky_coords[:,0], sky_coords[:,1]]\n",
    "labels_pred_clouds = labels_reshape[clouds_coords[:,0], clouds_coords[:,1]]\n",
    "labels_pred_veg = labels_reshape[veg_coords[:,0], veg_coords[:,1]]\n",
    "labels_pred_wtr = labels_reshape[wtr_coords[:,0], wtr_coords[:,1]]\n",
    "labels_pred_blt = labels_reshape[blt_coords[:,0], blt_coords[:,1]]\n",
    "labels_pred_windows = labels_reshape[windows_coords[:,0], windows_coords[:,1]]\n",
    "labels_pred_rds = labels_reshape[rds_coords[:,0], rds_coords[:,1]]\n",
    "labels_pred_cars = labels_reshape[cars_coords[:,0], cars_coords[:,1]]\n",
    "labels_pred_mtl = labels_reshape[mtl_coords[:,0], mtl_coords[:,1]]\n",
    "\n",
    "labels_pred = np.concatenate((labels_pred_sky, labels_pred_clouds, labels_pred_veg, labels_pred_wtr, \n",
    "                             labels_pred_blt, labels_pred_windows, labels_pred_rds, labels_pred_cars, labels_pred_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true_sky = np.full((sky_coords.shape[0]), 0)\n",
    "labels_true_clouds = np.full((clouds_coords.shape[0]), 1)\n",
    "labels_true_veg = np.full((veg_coords.shape[0]), 2)\n",
    "labels_true_wtr = np.full((wtr_coords.shape[0]), 3)\n",
    "labels_true_blt = np.full((blt_coords.shape[0]), 4)\n",
    "labels_true_windows = np.full((windows_coords.shape[0]), 5)\n",
    "labels_true_rds = np.full((rds_coords.shape[0]), 6)\n",
    "labels_true_cars = np.full((cars_coords.shape[0]), 7)\n",
    "labels_true_mtl = np.full((mtl_coords.shape[0]), 8)\n",
    "\n",
    "labels_true = np.concatenate((labels_true_sky, labels_true_clouds, labels_true_veg, labels_true_wtr, \n",
    "                             labels_true_blt, labels_true_windows, labels_true_rds, labels_true_cars, labels_true_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_pred.shape)\n",
    "print(labels_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(labels_true, labels_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Rand Index Adjusted for Chance\")\n",
    "print(metrics.adjusted_rand_score(labels_true, labels_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Completeness, Homogeneity, V-measure\")\n",
    "print(metrics.homogeneity_completeness_v_measure(labels_true, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_dict, sky_dict_norm = kmeans_test_dictionary(labels_reshape, sky_coords, 9)\n",
    "clouds_dict, cloud_dict_norm = kmeans_test_dictionary(labels_reshape, clouds_coords, 9)\n",
    "veg_dict, veg_dict_norm = kmeans_test_dictionary(labels_reshape, veg_coords, 9)\n",
    "wtr_dict, wtr_dict_norm = kmeans_test_dictionary(labels_reshape, wtr_coords, 9)\n",
    "blt_dict, blt_dict_norm = kmeans_test_dictionary(labels_reshape, blt_coords, 9)\n",
    "windows_dict, windows_dict_norm = kmeans_test_dictionary(labels_reshape, windows_coords, 9)\n",
    "rds_dict, rds_dict_norm = kmeans_test_dictionary(labels_reshape, rds_coords, 9)\n",
    "cars_dict, cars_dict_norm = kmeans_test_dictionary(labels_reshape, cars_coords, 9)\n",
    "mtl_dict, mtl_dict_norm = kmeans_test_dictionary(labels_reshape, mtl_coords, 9)\n",
    "\n",
    "df_test = kmeans_test_dataframe(sky_dict, clouds_dict, veg_dict, wtr_dict,\n",
    "                                blt_dict, windows_dict, rds_dict, cars_dict, mtl_dict)\n",
    "print(df_test.transpose())\n",
    "df_test_norm = kmeans_test_dataframe(sky_dict, clouds_dict, veg_dict, wtr_dict,\n",
    "                                     blt_dict, windows_dict, rds_dict, cars_dict, mtl_dict)\n",
    "#print(\"\")\n",
    "#print(df_test_norm.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_test, norm=False)\n",
    "#plot_confusion_matrix(df_test_norm, norm=True)\n",
    "plot_test_result(df_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as ListedColorMap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "veg_by_row = np.zeros(cube_sub.shape[1])\n",
    "for row in range(0, cube_sub.shape[1]):\n",
    "    veg_by_row[row] = np.count_nonzero(labels_reshape[row,:] == 7)# + np.count_nonzero(labels_reshape[row,:] == 8) + np.count_nonzero(labels_reshape[row,:] == 9)\n",
    "\n",
    "t=1\n",
    "cmap = {0:[0.0,0.63,0.87,t/4], 1:[0.0,0.63,0.87,t], 2:[0.74,0.74,0.74,t],  3:[1.0,0.1,0.1,t/4],\n",
    "        4:[0.0,0.63,0.87,t*3/4], 5:[0.0,0.63,0.87,t/2], 6:[0.93,0.91,0.77,t], 7:[1.0,0.1,0.1,t/2],\n",
    "        8:[1.0,0.1,0.1,t]}\n",
    "labels = {0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8', 9:'9', 10:'10', 11:'11'}\n",
    "arrayShow = np.array([[cmap[i] for i in j] for j in labels_reshape])\n",
    "patches = [mpatches.Patch(color=cmap[i], label=labels[i]) for i in cmap]\n",
    "#fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "fig = plt.figure(1, figsize=(30,10))\n",
    "axImage = plt.axes([0.1,0.1,0.65,0.95])\n",
    "axHist = plt.axes([0.75,0.1,0.2,0.95])\n",
    "axHist.yaxis.set_major_formatter(NullFormatter())\n",
    "axImage.tick_params(labelsize=20)\n",
    "axHist.tick_params(labelsize=20)\n",
    "axImage.imshow(arrayShow, aspect=0.5)\n",
    "lgd = axImage.legend(handles=patches, bbox_to_anchor=(0.5,1), loc=9, borderaxespad=-2.0, prop={'size':25}, ncol=12)\n",
    "axHist.plot(veg_by_row, np.arange(0,cube_sub.shape[1]), color=[0.0,0.33,0.62])\n",
    "axHist.fill_between(veg_by_row, np.arange(0,cube_sub.shape[1]), cube_sub.shape[1], facecolor=[0.0,0.33,0.62])\n",
    "axHist.set_ylim(cube_sub.shape[1], 0)\n",
    "axHist.set(title='Vegetation Pixels by Row')\n",
    "axHist.title.set_fontsize(25)\n",
    "plt.show()\n",
    "#fig.savefig(\"./output/plots/19_kmeans_clustering_of_veg_00108.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## KMeans on veg_00000 (South Facing @ ~6pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname0 = \"../../../image_files/veg_00000.raw\"\n",
    "cube0 = read_hyper(fname0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_sub0 = cube0.data[:, :, :].astype(float)\n",
    "print(cube_sub0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_reshaped0 = cube_sub0.transpose(1, 2, 0).reshape((cube_sub0.shape[1] * cube_sub0.shape[2]), cube_sub0.shape[0])\n",
    "print(cube_reshaped0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_standard0 = (cube_reshaped0 - cube_reshaped0.mean(1, keepdims=True)) / cube_reshaped0.std(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_norm0 = (cube_reshaped0 - cube_reshaped0.min()) / (cube_reshaped0.max() - cube_reshaped0.min())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "red_ind0 = (np.abs(cube0.waves - 650.0)).argmin()\n",
    "green_ind0 = (np.abs(cube0.waves - 550.0)).argmin()\n",
    "blue_ind0 = (np.abs(cube0.waves - 450.0)).argmin()\n",
    "\n",
    "cube_reshaped02 = cube_norm0.reshape(cube_sub0.shape[1], cube_sub0.shape[2], cube_sub0.shape[0])\n",
    "cube_scene0 = cube_reshaped02[:, :, [red_ind0, green_ind0, blue_ind0]]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('veg_00000 RGB Image')\n",
    "ax.imshow(cube_scene0, aspect=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb0 = cube_reshaped02[:, :, [red_ind0, green_ind0, blue_ind0]].copy()\n",
    "rgb0 /= rgb0.mean((0, 1), keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('veg_00000 corrected RGB Image')\n",
    "ax.imshow(rgb0, aspect=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create position array and normalize\n",
    "\n",
    "xycoords0 = coords(cube_sub0.shape[1], cube_sub0.shape[2])\n",
    "xycoords0 = xycoords0/xycoords0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append row, col position matrix to spectral data\n",
    "\n",
    "cube_temp0 = cube_standard0.reshape(cube_sub0.shape[1], cube_sub0.shape[2], cube_sub0.shape[0])\n",
    "cube_specxy0 = np.append(cube_temp0, xycoords0, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape spectral and spatial cube for clustering\n",
    "cube_specxy0_2d = cube_specxy0.reshape((cube_specxy0.shape[0] * cube_specxy0.shape[1]), cube_specxy0.shape[2])\n",
    "print(cube_specxy0_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_std0 = kmeans.predict(cube_specxy0_2d)\n",
    "labels_reshape0 = labels_std0.reshape(cube_sub0.shape[1], cube_sub0.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize=(12, 12))\n",
    "plt.suptitle('Mean Spectra of KMeans Clusters (veg_00000)')\n",
    "ax1.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 0)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax2.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 1)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax3.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 2)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax4.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 3)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax5.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 4)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax6.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 5)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax7.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 6)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax8.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 7)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax9.plot(cube0.waves, cube_standard0[np.where(labels_reshape0 == 8)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "plt.show()\n",
    "#f.savefig(\"./output/plots/13_kmeans_cluster_centers_spectra_standardized_4_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Paired9\n",
    "from bokeh.models import (ColorBar, LinearColorMapper)\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "labels_reverse0 = np.flip(labels_reshape0, axis=0)\n",
    "color_mapper = LinearColorMapper(palette=\"Paired9\", low=labels_reverse0.min(), \n",
    "                                 high=labels_reverse0.max())\n",
    "\n",
    "source_data = dict(image=[labels_reverse0],\n",
    "                  x=[0],\n",
    "                  y=[0],\n",
    "                  dw=[1600],\n",
    "                  dh=[1600])\n",
    "\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [\n",
    "    (\"Label\", \"@image\"),\n",
    "    (\"x\", \"@x\"),\n",
    "    (\"y\", \"@y\"),\n",
    "]\n",
    "\n",
    "output_notebook()\n",
    "imgplt = figure(plot_width=800, plot_height=400, x_range=(0,1600), y_range=(0,1600),\n",
    "               tools=['pan','tap','box_zoom','wheel_zoom','save','reset'],\n",
    "               title=\"Clustered Standardized Spectra (veg_00000)\")\n",
    "imgplt.image(source=source_data, image='image', x='x', y='y', dw='dw', dh='dh',\n",
    "            color_mapper = color_mapper)\n",
    "imgplt.add_layout(ColorBar(color_mapper = color_mapper), 'left')\n",
    "imgplt.tools.append(hover)\n",
    "show(imgplt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read test sample (veg_00000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read manually selected coordinates files\n",
    "\n",
    "#sky coordinates\n",
    "sky_file0 = open(\"../../manual_classified_pixels/1_sky_coordinates_000.txt\", \"r\")\n",
    "sky_coords0 = sky_file0.readlines()\n",
    "sky_file0.close()\n",
    "sky_coords0 = np.array([point_from_string(line) for line in sky_coords0])\n",
    "print(\"sky:        \", sky_coords0.shape)\n",
    "\n",
    "#clouds coordinates\n",
    "clouds_file0 = open(\"../../manual_classified_pixels/2_clouds_coordinates_000.txt\", \"r\")\n",
    "clouds_coords0 = clouds_file0.readlines()\n",
    "clouds_file0.close()\n",
    "clouds_coords0 = np.array([point_from_string(line) for line in clouds_coords0])\n",
    "print(\"clouds:     \", clouds_coords0.shape)\n",
    "\n",
    "#vegetation coordinates\n",
    "veg_file0 = open(\"../../manual_classified_pixels/3_vegetation_coordinates_000.txt\", \"r\")\n",
    "veg_coords0 = veg_file0.readlines()\n",
    "veg_file0.close()\n",
    "veg_coords0 = np.array([point_from_string(line) for line in veg_coords0])\n",
    "print(\"vegetation: \", veg_coords0.shape)\n",
    "\n",
    "#water coordinates\n",
    "wtr_file0 = open(\"../../manual_classified_pixels/4_water_coordinates_000.txt\", \"r\")\n",
    "wtr_coords0 = wtr_file0.readlines()\n",
    "wtr_file0.close()\n",
    "wtr_coords0 = np.array([point_from_string(line) for line in wtr_coords0])\n",
    "print(\"water:      \", wtr_coords0.shape)\n",
    "\n",
    "#buildings coordinates\n",
    "blt_file0 = open(\"../../manual_classified_pixels/5_buildings_coordinates_000.txt\", \"r\")\n",
    "blt_coords0 = blt_file0.readlines()\n",
    "blt_file0.close()\n",
    "blt_coords0 = np.array([point_from_string(line) for line in blt_coords0])\n",
    "print(\"buildings:  \", blt_coords0.shape)\n",
    "\n",
    "#windows coordinates\n",
    "windows_file0 = open(\"../../manual_classified_pixels/6_windows_coordinates_000.txt\", \"r\")\n",
    "windows_coords0 = windows_file0.readlines()\n",
    "windows_file0.close()\n",
    "windows_coords0 = np.array([point_from_string(line) for line in windows_coords0])\n",
    "print(\"windows:    \", windows_coords0.shape)\n",
    "\n",
    "#roads coordinates\n",
    "rds_file0 = open(\"../../manual_classified_pixels/7_roads_coordinates_000.txt\", \"r\")\n",
    "rds_coords0 = rds_file0.readlines()\n",
    "rds_file0.close()\n",
    "rds_coords0 = np.array([point_from_string(line) for line in rds_coords0])\n",
    "print(\"road:       \", rds_coords0.shape)\n",
    "\n",
    "#cars coordinates\n",
    "cars_file0 = open(\"../../manual_classified_pixels/8_cars_coordinates_000.txt\", \"r\")\n",
    "cars_coords0 = cars_file0.readlines()\n",
    "cars_file0.close()\n",
    "cars_coords0 = np.array([point_from_string(line) for line in cars_coords0])\n",
    "print(\"cars:       \", cars_coords0.shape)\n",
    "\n",
    "#metal coordinates\n",
    "mtl_file0 = open(\"../../manual_classified_pixels/9_metal_coordinates_000.txt\", \"r\")\n",
    "mtl_coords0 = mtl_file0.readlines()\n",
    "mtl_file0.close()\n",
    "mtl_coords0 = np.array([point_from_string(line) for line in mtl_coords0])\n",
    "print(\"metal:      \", mtl_coords0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtr_coords0=np.array([[0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0_pred_sky = labels_reshape0[sky_coords0[:,0], sky_coords0[:,1]]\n",
    "labels0_pred_clouds = labels_reshape0[clouds_coords0[:,0], clouds_coords0[:,1]]\n",
    "labels0_pred_veg = labels_reshape0[veg_coords0[:,0], veg_coords0[:,1]]\n",
    "labels0_pred_wtr = labels_reshape0[wtr_coords0[:,0], wtr_coords0[:,1]]\n",
    "labels0_pred_blt = labels_reshape0[blt_coords0[:,0], blt_coords0[:,1]]\n",
    "labels0_pred_windows = labels_reshape0[windows_coords0[:,0], windows_coords0[:,1]]\n",
    "labels0_pred_rds = labels_reshape0[rds_coords0[:,0], rds_coords0[:,1]]\n",
    "labels0_pred_cars = labels_reshape0[cars_coords0[:,0], cars_coords0[:,1]]\n",
    "labels0_pred_mtl = labels_reshape0[mtl_coords0[:,0], mtl_coords0[:,1]]\n",
    "\n",
    "labels0_pred = np.concatenate((labels0_pred_sky, labels0_pred_clouds, labels0_pred_veg, labels0_pred_wtr, \n",
    "                             labels0_pred_blt, labels0_pred_windows, labels0_pred_rds, labels0_pred_cars, labels0_pred_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0_true_sky = np.full((sky_coords0.shape[0]), 0)\n",
    "labels0_true_clouds = np.full((clouds_coords0.shape[0]), 1)\n",
    "labels0_true_veg = np.full((veg_coords0.shape[0]), 2)\n",
    "labels0_true_wtr = np.full((wtr_coords0.shape[0]), 3)\n",
    "labels0_true_blt = np.full((blt_coords0.shape[0]), 4)\n",
    "labels0_true_windows = np.full((windows_coords0.shape[0]), 5)\n",
    "labels0_true_rds = np.full((rds_coords0.shape[0]), 6)\n",
    "labels0_true_cars = np.full((cars_coords0.shape[0]), 7)\n",
    "labels0_true_mtl = np.full((mtl_coords0.shape[0]), 8)\n",
    "\n",
    "labels0_true = np.concatenate((labels0_true_sky, labels0_true_clouds, labels0_true_veg, labels0_true_wtr, \n",
    "                             labels0_true_blt, labels0_true_windows, labels0_true_rds, labels0_true_cars, labels0_true_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels0_pred.shape)\n",
    "print(labels0_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(labels0_true, labels0_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Rand Index Adjusted for Chance\")\n",
    "print(metrics.adjusted_rand_score(labels0_true, labels0_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Completeness, Homogeneity, V-measure\")\n",
    "print(metrics.homogeneity_completeness_v_measure(labels0_true, labels0_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_dict0, sky_dict_norm0 = kmeans_test_dictionary(labels_reshape0, sky_coords0, 9)\n",
    "clouds_dict0, cloud_dict_norm0 = kmeans_test_dictionary(labels_reshape0, clouds_coords0, 9)\n",
    "veg_dict0, veg_dict_norm0 = kmeans_test_dictionary(labels_reshape0, veg_coords0, 9)\n",
    "wtr_dict0, wtr_dict_norm0 = kmeans_test_dictionary(labels_reshape0, wtr_coords0, 9)\n",
    "blt_dict0, blt_dict_norm0 = kmeans_test_dictionary(labels_reshape0, blt_coords0, 9)\n",
    "windows_dict0, windows_dict_norm0 = kmeans_test_dictionary(labels_reshape0, windows_coords0, 9)\n",
    "rds_dict0, rds_dict_norm0 = kmeans_test_dictionary(labels_reshape0, rds_coords0, 9)\n",
    "cars_dict0, cars_dict_norm0 = kmeans_test_dictionary(labels_reshape0, cars_coords0, 9)\n",
    "mtl_dict0, mtl_dict_norm0 = kmeans_test_dictionary(labels_reshape0, mtl_coords0, 9)\n",
    "\n",
    "df_test0 = kmeans_test_dataframe(sky_dict0, clouds_dict0, veg_dict0, wtr_dict0,\n",
    "                                blt_dict0, windows_dict0, rds_dict0, cars_dict0, mtl_dict0)\n",
    "print(df_test0.transpose())\n",
    "df_test_norm0 = kmeans_test_dataframe(sky_dict0, clouds_dict0, veg_dict0, wtr_dict0,\n",
    "                                     blt_dict0, windows_dict0, rds_dict0, cars_dict0, mtl_dict0)\n",
    "#print(\"\")\n",
    "#print(df_test_norm0.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_test0, norm=False)\n",
    "#plot_confusion_matrix(df_test_norm0, norm=True)\n",
    "plot_test_result(df_test_norm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as ListedColorMap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "veg_by_row0 = np.zeros(cube_sub0.shape[1])\n",
    "for row in range(0, cube_sub0.shape[1]):\n",
    "    veg_by_row0[row] = np.count_nonzero(labels_reshape0[row,:] == 7)# + np.count_nonzero(labels_reshape[row,:] == 8) + np.count_nonzero(labels_reshape[row,:] == 9)\n",
    "\n",
    "t=1\n",
    "cmap = {0:[0.0,0.63,0.87,t/4], 1:[0.0,0.63,0.87,t], 2:[0.74,0.74,0.74,t],  3:[1.0,0.1,0.1,t/4],\n",
    "        4:[0.0,0.63,0.87,t*3/4], 5:[0.0,0.63,0.87,t/2], 6:[0.93,0.91,0.77,t], 7:[1.0,0.1,0.1,t/2],\n",
    "        8:[1.0,0.1,0.1,t]}\n",
    "labels = {0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8', 9:'9', 10:'10', 11:'11'}\n",
    "arrayShow = np.array([[cmap[i] for i in j] for j in labels_reshape0])\n",
    "patches = [mpatches.Patch(color=cmap[i], label=labels[i]) for i in cmap]\n",
    "#fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "fig = plt.figure(1, figsize=(30,10))\n",
    "axImage = plt.axes([0.1,0.1,0.65,0.95])\n",
    "axHist = plt.axes([0.75,0.1,0.2,0.95])\n",
    "axHist.yaxis.set_major_formatter(NullFormatter())\n",
    "axImage.tick_params(labelsize=20)\n",
    "axHist.tick_params(labelsize=20)\n",
    "axImage.imshow(arrayShow, aspect=0.5)\n",
    "lgd = axImage.legend(handles=patches, bbox_to_anchor=(0.5,1), loc=9, borderaxespad=-2.0, prop={'size':25}, ncol=12)\n",
    "axHist.plot(veg_by_row0, np.arange(0,cube_sub.shape[1]), color=[0.0,0.33,0.62])\n",
    "axHist.fill_between(veg_by_row0, np.arange(0,cube_sub.shape[1]), cube_sub.shape[1], facecolor=[0.0,0.33,0.62])\n",
    "axHist.set_ylim(cube_sub.shape[1], 0)\n",
    "axHist.set(title='Vegetation Pixels by Row')\n",
    "axHist.title.set_fontsize(25)\n",
    "plt.show()\n",
    "#fig.savefig(\"./output/plots/19_kmeans_clustering_of_veg_00108.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## KMeans on North Facing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_north = \"../../../image_files/scan1_slow_roof_VNIR.raw\"\n",
    "cube_north = read_hyper(fname_north)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_sub_north = cube_north.data[:, :, :].astype(float)\n",
    "print(cube_sub_north.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_reshaped_north = cube_sub_north.transpose(1, 2, 0).reshape((cube_sub_north.shape[1] * cube_sub_north.shape[2]), cube_sub_north.shape[0])\n",
    "print(cube_reshaped_north.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_norm_north = (cube_reshaped_north - cube_reshaped_north.min()) / (cube_reshaped_north.max() - cube_reshaped_north.min())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "red_ind_n = (np.abs(cube_north.waves - 650.0)).argmin()\n",
    "green_ind_n = (np.abs(cube_north.waves - 550.0)).argmin()\n",
    "blue_ind_n = (np.abs(cube_north.waves - 450.0)).argmin()\n",
    "\n",
    "cube_reshaped_north2 = cube_norm_north.reshape(cube_sub_north.shape[1], cube_sub_north.shape[2], cube_sub_north.shape[0])\n",
    "cube_scene_north = cube_reshaped_north2[:, :, [red_ind_n, green_ind_n, blue_ind_n]]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('North Facing RGB Image')\n",
    "ax.imshow(cube_scene_north, aspect=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbn = cube_reshaped_north2[:, :, [red_ind_n, green_ind_n, blue_ind_n]].copy()\n",
    "rgbn /= rgbn.mean((0, 1), keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('North Facing corrected RGB Image')\n",
    "ax.imshow(rgbn.clip(0, 1)**0.5, aspect=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_standard_north = (cube_reshaped_north - cube_reshaped_north.mean(1, keepdims=True)) / cube_reshaped_north.std(1, keepdims=True)\n",
    "cube_reshaped_north = cube_standard_north"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cube.waves))\n",
    "print(min(cube.waves), max(cube.waves))\n",
    "print()\n",
    "print(len(cube_north.waves))\n",
    "print(min(cube_north.waves), max(cube_north.waves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolating an extrapolating the north facing scene\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "interp_hsi = interp1d(cube_north.waves, cube_reshaped_north, axis=1, fill_value=\"extrapolate\")\n",
    "northri = interp_hsi(cube.waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax.plot(cube_north.waves, cube_reshaped_north[1000, :], \".\", color=\"r\")\n",
    "ax.plot(cube.waves, northri[1000, :], 'o', ms=3, color=\"b\")\n",
    "ax.plot(cube_north.waves, cube_reshaped_north[1000, :], \".\", ms=3, color=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cube_reshaped_north.shape)\n",
    "print(northri.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create position array and normalize\n",
    "\n",
    "xycoordsn = coords(cube_sub_north.shape[1], cube_sub_north.shape[2])\n",
    "xycoordsn = xycoordsn/xycoordsn.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append row, col position matrix to spectral data\n",
    "\n",
    "cube_tempn = northri.reshape(cube_sub_north.shape[1], cube_sub_north.shape[2], northri.shape[1])\n",
    "cube_specxyn = np.append(cube_tempn, xycoordsn, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape spectral and spatial cube for clustering\n",
    "cube_specxyn_2d = cube_specxyn.reshape((cube_specxyn.shape[0] * cube_specxyn.shape[1]), cube_specxyn.shape[2])\n",
    "print(cube_specxyn_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_north = kmeans.predict(cube_specxyn_2d)\n",
    "labels_reshape_north = labels_north.reshape(cube_sub_north.shape[1], cube_sub_north.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize=(12, 12))\n",
    "plt.suptitle('Mean Spectra of KMeans Clusters (north facing)')\n",
    "ax1.plot(cube.waves, northri[np.where(labels_reshape_north == 0)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax2.plot(cube.waves, northri[np.where(labels_reshape_north == 1)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax3.plot(cube.waves, northri[np.where(labels_reshape_north == 2)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax4.plot(cube.waves, northri[np.where(labels_reshape_north == 3)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax5.plot(cube.waves, northri[np.where(labels_reshape_north == 4)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax6.plot(cube.waves, northri[np.where(labels_reshape_north == 5)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax7.plot(cube.waves, northri[np.where(labels_reshape_north == 6)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax8.plot(cube.waves, northri[np.where(labels_reshape_north == 7)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "ax9.plot(cube.waves, northri[np.where(labels_reshape_north == 8)[0]].mean(0), color=[0.0,0.33,0.62])\n",
    "plt.show()\n",
    "#f.savefig(\"./output/plots/13_kmeans_cluster_centers_spectra_standardized_4_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Paired9\n",
    "from bokeh.models import (ColorBar, LinearColorMapper)\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "labels_reverse_north = np.flip(labels_reshape_north, axis=0)\n",
    "color_mapper = LinearColorMapper(palette=\"Paired9\", low=labels_reverse_north.min(), \n",
    "                                 high=labels_reverse_north.max())\n",
    "\n",
    "source_data = dict(image=[labels_reverse_north],\n",
    "                  x=[0],\n",
    "                  y=[0],\n",
    "                  dw=[1247],\n",
    "                  dh=[1600])\n",
    "\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [\n",
    "    (\"Label\", \"@image\"),\n",
    "    (\"x\", \"@x\"),\n",
    "    (\"y\", \"@y\"),\n",
    "]\n",
    "\n",
    "output_notebook()\n",
    "imgplt = figure(plot_width=625, plot_height=400, x_range=(0,1247), y_range=(0,1600),\n",
    "               tools=['pan','tap','box_zoom','wheel_zoom','save','reset'],\n",
    "               title=\"Clustered Standardized Spectra (north facing)\")\n",
    "imgplt.image(source=source_data, image='image', x='x', y='y', dw='dw', dh='dh',\n",
    "            color_mapper = color_mapper)\n",
    "imgplt.add_layout(ColorBar(color_mapper = color_mapper), 'left')\n",
    "imgplt.tools.append(hover)\n",
    "show(imgplt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read test sample (north facing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read manually selected coordinates files\n",
    "\n",
    "#sky coordinates\n",
    "sky_filen = open(\"../../manual_classified_pixels/1_sky_coordinates_north.txt\", \"r\")\n",
    "sky_coordsn = sky_filen.readlines()\n",
    "sky_filen.close()\n",
    "sky_coordsn = np.array([point_from_string(line) for line in sky_coordsn])\n",
    "print(\"sky:        \", sky_coordsn.shape)\n",
    "\n",
    "#clouds coordinates\n",
    "clouds_filen = open(\"../../manual_classified_pixels/2_clouds_coordinates_north.txt\", \"r\")\n",
    "clouds_coordsn = clouds_filen.readlines()\n",
    "clouds_filen.close()\n",
    "clouds_coordsn = np.array([point_from_string(line) for line in clouds_coordsn])\n",
    "print(\"clouds:     \", clouds_coordsn.shape)\n",
    "\n",
    "#vegetation coordinates\n",
    "veg_filen = open(\"../../manual_classified_pixels/3_vegetation_coordinates_north.txt\", \"r\")\n",
    "veg_coordsn = veg_filen.readlines()\n",
    "veg_filen.close()\n",
    "veg_coordsn = np.array([point_from_string(line) for line in veg_coordsn])\n",
    "print(\"vegetation: \", veg_coordsn.shape)\n",
    "\n",
    "#water coordinates\n",
    "wtr_filen = open(\"../../manual_classified_pixels/4_water_coordinates_north.txt\", \"r\")\n",
    "wtr_coordsn = wtr_filen.readlines()\n",
    "wtr_filen.close()\n",
    "wtr_coordsn = np.array([point_from_string(line) for line in wtr_coordsn])\n",
    "print(\"water:      \", wtr_coordsn.shape)\n",
    "\n",
    "#buildings coordinates\n",
    "blt_filen = open(\"../../manual_classified_pixels/5_buildings_coordinates_north.txt\", \"r\")\n",
    "blt_coordsn = blt_filen.readlines()\n",
    "blt_filen.close()\n",
    "blt_coordsn = np.array([point_from_string(line) for line in blt_coordsn])\n",
    "print(\"buildings:  \", blt_coordsn.shape)\n",
    "\n",
    "#windows coordinates\n",
    "windows_filen = open(\"../../manual_classified_pixels/6_windows_coordinates_north.txt\", \"r\")\n",
    "windows_coordsn = windows_filen.readlines()\n",
    "windows_filen.close()\n",
    "windows_coordsn = np.array([point_from_string(line) for line in windows_coordsn])\n",
    "print(\"windows:    \", windows_coordsn.shape)\n",
    "\n",
    "#roads coordinates\n",
    "rds_filen = open(\"../../manual_classified_pixels/7_roads_coordinates_north.txt\", \"r\")\n",
    "rds_coordsn = rds_filen.readlines()\n",
    "rds_filen.close()\n",
    "rds_coordsn = np.array([point_from_string(line) for line in rds_coordsn])\n",
    "print(\"road:       \", rds_coordsn.shape)\n",
    "\n",
    "#cars coordinates\n",
    "cars_filen = open(\"../../manual_classified_pixels/8_cars_coordinates_north.txt\", \"r\")\n",
    "cars_coordsn = cars_filen.readlines()\n",
    "cars_filen.close()\n",
    "cars_coordsn = np.array([point_from_string(line) for line in cars_coordsn])\n",
    "print(\"cars:       \", cars_coordsn.shape)\n",
    "\n",
    "#metal coordinates\n",
    "mtl_filen = open(\"../../manual_classified_pixels/9_metal_coordinates_north.txt\", \"r\")\n",
    "mtl_coordsn = mtl_filen.readlines()\n",
    "mtl_filen.close()\n",
    "mtl_coordsn = np.array([point_from_string(line) for line in mtl_coordsn])\n",
    "print(\"metal:      \", mtl_coordsn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsn_pred_sky = labels_reshape_north[sky_coordsn[:,0], sky_coordsn[:,1]]\n",
    "labelsn_pred_clouds = labels_reshape_north[clouds_coordsn[:,0], clouds_coordsn[:,1]]\n",
    "labelsn_pred_veg = labels_reshape_north[veg_coordsn[:,0], veg_coordsn[:,1]]\n",
    "labelsn_pred_wtr = labels_reshape_north[wtr_coordsn[:,0], wtr_coordsn[:,1]]\n",
    "labelsn_pred_blt = labels_reshape_north[blt_coordsn[:,0], blt_coordsn[:,1]]\n",
    "labelsn_pred_windows = labels_reshape_north[windows_coordsn[:,0], windows_coordsn[:,1]]\n",
    "labelsn_pred_rds = labels_reshape_north[rds_coordsn[:,0], rds_coordsn[:,1]]\n",
    "labelsn_pred_cars = labels_reshape_north[cars_coordsn[:,0], cars_coordsn[:,1]]\n",
    "labelsn_pred_mtl = labels_reshape_north[mtl_coordsn[:,0], mtl_coordsn[:,1]]\n",
    "\n",
    "labelsn_pred = np.concatenate((labelsn_pred_sky, labelsn_pred_clouds, labelsn_pred_veg, labelsn_pred_wtr, \n",
    "                             labelsn_pred_blt, labelsn_pred_windows, labelsn_pred_rds, labelsn_pred_cars, labelsn_pred_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsn_true_sky = np.full((sky_coordsn.shape[0]), 0)\n",
    "labelsn_true_clouds = np.full((clouds_coordsn.shape[0]), 1)\n",
    "labelsn_true_veg = np.full((veg_coordsn.shape[0]), 2)\n",
    "labelsn_true_wtr = np.full((wtr_coordsn.shape[0]), 3)\n",
    "labelsn_true_blt = np.full((blt_coordsn.shape[0]), 4)\n",
    "labelsn_true_windows = np.full((windows_coordsn.shape[0]), 5)\n",
    "labelsn_true_rds = np.full((rds_coordsn.shape[0]), 6)\n",
    "labelsn_true_cars = np.full((cars_coordsn.shape[0]), 7)\n",
    "labelsn_true_mtl = np.full((mtl_coordsn.shape[0]), 8)\n",
    "\n",
    "labelsn_true = np.concatenate((labelsn_true_sky, labelsn_true_clouds, labelsn_true_veg, labelsn_true_wtr, \n",
    "                             labelsn_true_blt, labelsn_true_windows, labelsn_true_rds, labelsn_true_cars, labelsn_true_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labelsn_pred.shape)\n",
    "print(labelsn_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(labelsn_true, labelsn_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Rand Index Adjusted for Chance\")\n",
    "print(metrics.adjusted_rand_score(labelsn_true, labelsn_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Completeness, Homogeneity, V-measure\")\n",
    "print(metrics.homogeneity_completeness_v_measure(labelsn_true, labelsn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_dictn, sky_dict_normn = kmeans_test_dictionary(labels_reshape_north, sky_coordsn, 9)\n",
    "clouds_dictn, cloud_dict_normn = kmeans_test_dictionary(labels_reshape_north, clouds_coordsn, 9)\n",
    "veg_dictn, veg_dict_normn = kmeans_test_dictionary(labels_reshape_north, veg_coordsn, 9)\n",
    "wtr_dictn, wtr_dict_normn = kmeans_test_dictionary(labels_reshape_north, wtr_coordsn, 9)\n",
    "blt_dictn, blt_dict_normn = kmeans_test_dictionary(labels_reshape_north, blt_coordsn, 9)\n",
    "windows_dictn, windows_dict_normn = kmeans_test_dictionary(labels_reshape_north, windows_coordsn, 9)\n",
    "rds_dictn, rds_dict_normn = kmeans_test_dictionary(labels_reshape_north, rds_coordsn, 9)\n",
    "cars_dictn, cars_dict_normn = kmeans_test_dictionary(labels_reshape_north, cars_coordsn, 9)\n",
    "mtl_dictn, mtl_dict_normn = kmeans_test_dictionary(labels_reshape_north, mtl_coordsn, 9)\n",
    "\n",
    "df_testn = kmeans_test_dataframe(sky_dictn, clouds_dictn, veg_dictn, wtr_dictn,\n",
    "                                blt_dictn, windows_dictn, rds_dictn, cars_dictn, mtl_dictn)\n",
    "print(df_testn.transpose())\n",
    "df_test_normn = kmeans_test_dataframe(sky_dictn, clouds_dictn, veg_dictn, wtr_dictn,\n",
    "                                     blt_dictn, windows_dictn, rds_dictn, cars_dictn, mtl_dictn)\n",
    "#print(\"\")\n",
    "#print(df_test_normn.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_testn, norm=False)\n",
    "#plot_confusion_matrix(df_test_normn, norm=True)\n",
    "plot_test_result(df_test_normn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as ListedColorMap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "veg_by_row_north = np.zeros(cube_sub_north.shape[1])\n",
    "for row in range(0, cube_sub_north.shape[1]):\n",
    "    veg_by_row_north[row] = np.count_nonzero(labels_reshape_north[row,:] == 7)# + np.count_nonzero(labels_reshape[row,:] == 8) + np.count_nonzero(labels_reshape[row,:] == 9)\n",
    "\n",
    "t=1\n",
    "cmap = {0:[0.0,0.63,0.87,t/4], 1:[0.0,0.63,0.87,t], 2:[0.74,0.74,0.74,t],  3:[1.0,0.1,0.1,t/4],\n",
    "        4:[0.0,0.63,0.87,t*3/4], 5:[0.0,0.63,0.87,t/2], 6:[0.93,0.91,0.77,t], 7:[1.0,0.1,0.1,t/2],\n",
    "        8:[1.0,0.1,0.1,t]}\n",
    "labels = {0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8', 9:'9', 10:'10', 11:'11'}\n",
    "arrayShow = np.array([[cmap[i] for i in j] for j in labels_reshape_north])\n",
    "patches = [mpatches.Patch(color=cmap[i], label=labels[i]) for i in cmap]\n",
    "#fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "fig = plt.figure(1, figsize=(30,10))\n",
    "axImage = plt.axes([0.1,0.1,0.65,0.95])\n",
    "axHist = plt.axes([0.75,0.1,0.2,0.95])\n",
    "axHist.yaxis.set_major_formatter(NullFormatter())\n",
    "axImage.tick_params(labelsize=20)\n",
    "axHist.tick_params(labelsize=20)\n",
    "axImage.imshow(arrayShow, aspect=0.5)\n",
    "lgd = axImage.legend(handles=patches, bbox_to_anchor=(0.5,1), loc=9, borderaxespad=-2.0, prop={'size':25}, ncol=12)\n",
    "axHist.plot(veg_by_row_north, np.arange(0,cube_sub_north.shape[1]), color=[0.0,0.33,0.62])\n",
    "axHist.fill_between(veg_by_row_north, np.arange(0,cube_sub_north.shape[1]), cube_sub_north.shape[1], facecolor=[0.0,0.33,0.62])\n",
    "axHist.set_ylim(cube_sub_north.shape[1], 0)\n",
    "axHist.set(title='Vegetation Pixels by Row')\n",
    "axHist.title.set_fontsize(25)\n",
    "plt.show()\n",
    "#fig.savefig(\"./output/plots/19_kmeans_clustering_of_veg_00108.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
