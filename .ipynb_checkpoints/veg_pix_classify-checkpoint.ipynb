{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of Hyperspectral Vegetation Image veg_00108\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- here are functions that generate a class that memory maps the raw data \n",
    "#    cube.  After executing this cell, the syntax is:\n",
    "#    fname = \"[path to data]/foo.raw\"\n",
    "#    cube = read_hyper(fname)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def read_header(hdrfile, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a Middleton header file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hdrfile : str\n",
    "        Name of header file.\n",
    "    verbose : bool, optional\n",
    "        If True, alert the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : dict\n",
    "        A dictionary continaing the number of rows, columns, and wavelengths\n",
    "        as well as an array of band centers.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- alert\n",
    "    if verbose:\n",
    "        print(\"reading and parsing {0}...\".format(hdrfile))\n",
    "\n",
    "    # -- open the file and read in the records\n",
    "    recs = [rec for rec in open(hdrfile)]\n",
    "\n",
    "    # -- parse for samples, lines, bands, and the start of the wavelengths\n",
    "    for irec, rec in enumerate(recs):\n",
    "        if 'samples' in rec:\n",
    "            samples = int(rec.split(\"=\")[1])\n",
    "        elif 'lines' in rec:\n",
    "            lines = int(rec.split(\"=\")[1])\n",
    "        elif 'bands' in rec:\n",
    "            bands = int(rec.split(\"=\")[1])\n",
    "        elif \"Wavelength\" in rec:\n",
    "            w0ind = irec+1\n",
    "\n",
    "    # -- parse for the wavelengths\n",
    "    waves = np.array([float(rec.split(\",\")[0]) for rec in \n",
    "                      recs[w0ind:w0ind+bands]])\n",
    "\n",
    "    # -- return a dictionary\n",
    "    return {\"nrow\":samples, \"ncol\":lines, \"nwav\":bands, \"waves\":waves}\n",
    "\n",
    "\n",
    "def read_raw(rawfile, shape, hyper=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a Middleton raw file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rawfile : str\n",
    "        The name of the raw file.\n",
    "    shape : tuple\n",
    "        The output shape of the data cube (nwav, nrow, ncol).\n",
    "    hyper : bool, optional\n",
    "        Set this flag to read a hyperspectral image.\n",
    "    verbose : bool, optional\n",
    "        Alert the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    memmap : memmap\n",
    "        A numpy memmap of the datacube.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- alert\n",
    "    if verbose:\n",
    "        print(\"reading {0}...\".format(rawfile))\n",
    "\n",
    "    # -- read either broadband or hyperspectral image\n",
    "    if hyper:\n",
    "        return np.memmap(rawfile, np.uint16, mode=\"r\") \\\n",
    "            .reshape(shape[2], shape[0], shape[1])[:, :, ::-1] \\\n",
    "            .transpose(1, 2, 0)\n",
    "    else:\n",
    "        return np.memmap(rawfile, np.uint8, mode=\"r\") \\\n",
    "            .reshape(shape[1], shape[2], shape[0])[:, :, ::-1]\n",
    "\n",
    "\n",
    "def read_hyper(fpath, fname=None, full=True):\n",
    "    \"\"\"\n",
    "    Read a full hyperspectral scan (raw and header file).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fpath : str\n",
    "        Either the full name+path of the raw file or the path of the raw file.\n",
    "        If the latter, fname must be supplied.\n",
    "    fname : str, optional\n",
    "        The name of the raw file (required if fpath is set to a path).\n",
    "    full : bool, optional\n",
    "        If True, output a class containing data and supplementary information.\n",
    "        If False, output only the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output or memmap : class or memmap\n",
    "        If full is True, a class containing data plus supplementary \n",
    "        information.  If full is False, a memmap array of the data.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- set up the file names\n",
    "    if fname is not None:\n",
    "        fpath = os.path.join(fpath, fname)\n",
    "\n",
    "    # -- read the header\n",
    "    hdr = read_header(fpath.replace(\"raw\", \"hdr\"))\n",
    "    sh  = (hdr[\"nwav\"], hdr[\"nrow\"], hdr[\"ncol\"])\n",
    "\n",
    "    # -- if desired, only output data cube\n",
    "    if not full:\n",
    "        return read_raw(fpath, sh, hyper=True)\n",
    "\n",
    "    # -- output full structure\n",
    "    class output():\n",
    "        def __init__(self, fpath):\n",
    "            self.filename = fpath\n",
    "            self.data     = read_raw(fpath, sh, hyper=True)\n",
    "            self.waves    = hdr[\"waves\"]\n",
    "            self.nwav     = sh[0]\n",
    "            self.nrow     = sh[1]\n",
    "            self.ncol     = sh[2]\n",
    "\n",
    "    return output(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and parsing ../image_files/veg_00108.hdr...\n",
      "reading ../image_files/veg_00108.raw...\n"
     ]
    }
   ],
   "source": [
    "fname = \"../image_files/veg_00108.raw\"\n",
    "cube = read_hyper(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(848, 1600, 1600)\n"
     ]
    }
   ],
   "source": [
    "cube_sub = cube.data[:, :, :].astype(float)\n",
    "print(cube_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560000, 848)\n"
     ]
    }
   ],
   "source": [
    "cube_reshaped = cube_sub.transpose(1, 2, 0).reshape((cube_sub.shape[1] * cube_sub.shape[2]), cube_sub.shape[0])\n",
    "print(cube_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 42], [42, 84], [84, 126], [126, 168], [168, 210], [210, 252], [252, 294], [294, 336], [336, 378], [378, 420], [420, 462], [462, 504], [504, 546], [546, 588], [588, 630], [630, 672], [672, 714], [714, 756], [756, 798], [798, 840], [840, 848]]\n"
     ]
    }
   ],
   "source": [
    "# create array of indices\n",
    "\n",
    "num_of_bins = 20\n",
    "bin_ind = []\n",
    "\n",
    "for i in range(0, num_of_bins + 1):\n",
    "    low_ind = int(i*int(cube_sub.shape[0]/num_of_bins))\n",
    "    upp_ind = int(low_ind + int(cube_sub.shape[0]/num_of_bins))\n",
    "    bin_ind.append([low_ind, upp_ind])\n",
    "bin_ind[-1][-1] = cube_sub.shape[0]\n",
    "    \n",
    "print(bin_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560000, 20)\n"
     ]
    }
   ],
   "source": [
    "cube_binned = np.zeros(shape=(cube_reshaped.shape[0], num_of_bins))\n",
    "\n",
    "for i in range(num_of_bins):\n",
    "    cube_binned[:, i] = cube_reshaped[:, bin_ind[i][0]:bin_ind[i][1]].mean(1)\n",
    "\n",
    "print(cube_binned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read coordinates from file\n",
    "\n",
    "def point_from_string(text):\n",
    "    \n",
    "    items = text.strip(\"\\n\").split(\" \")\n",
    "    rind = int(items[0])\n",
    "    cind = int(items[1])\n",
    "    \n",
    "    return rind, cind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (1000,) (1000,)\n",
      "[[448 320]\n",
      " [462 244]] [448 462] [320 244]\n",
      "(600, 2)\n",
      "(1010, 2)\n"
     ]
    }
   ],
   "source": [
    "# read manually selected coordinates files\n",
    "\n",
    "# sky coordinates\n",
    "sky_file = open(\"./sky_coordinates.txt\", \"r\")\n",
    "sky_coords = sky_file.readlines()\n",
    "sky_file.close()\n",
    "sky_coords = np.array([point_from_string(line) for line in sky_coords])\n",
    "print(sky_coords.shape)\n",
    "\n",
    "# vegetation coordinates\n",
    "veg_file = open(\"./vegetation_coordinates.txt\", \"r\")\n",
    "veg_coords = veg_file.readlines()\n",
    "veg_file.close()\n",
    "veg_coords = np.array([point_from_string(line) for line in veg_coords])\n",
    "print(veg_coords.shape)\n",
    "\n",
    "# built coordinates\n",
    "built_file = open(\"./built_coordinates.txt\", \"r\")\n",
    "built_coords = built_file.readlines()\n",
    "built_file.close()\n",
    "built_coords = np.array([point_from_string(line) for line in built_coords])\n",
    "print(built_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sky 800 200\n",
      "veg 480 120\n",
      "built 808 202\n"
     ]
    }
   ],
   "source": [
    "# split manually selected pixels to 80% training and 20% testing sets\n",
    "import random\n",
    "\n",
    "# sky coordinates\n",
    "sky_ind = np.arange(sky_coords.shape[0])\n",
    "random.shuffle(sky_ind)\n",
    "lim_ind = int(len(sky_ind)*0.8)\n",
    "sky_train_ind = sky_ind[:lim_ind]\n",
    "sky_test_ind = sky_ind[lim_ind:]\n",
    "print(\"sky %d %d\" % (len(sky_train_ind), len(sky_test_ind)))\n",
    "\n",
    "# vegetation coordinates\n",
    "veg_ind = np.arange(veg_coords.shape[0])\n",
    "random.shuffle(veg_ind)\n",
    "lim_ind = int(len(veg_ind)*0.8)\n",
    "veg_train_ind = veg_ind[:lim_ind]\n",
    "veg_test_ind = veg_ind[lim_ind:]\n",
    "print(\"veg %d %d\" % (len(veg_train_ind), len(veg_test_ind)))\n",
    "\n",
    "# built coordinates\n",
    "built_ind = np.arange(built_coords.shape[0])\n",
    "random.shuffle(built_ind)\n",
    "lim_ind = int(len(built_ind)*0.8)\n",
    "built_train_ind = built_ind[:lim_ind]\n",
    "built_test_ind = built_ind[lim_ind:]\n",
    "print(\"built %d %d\" % (len(built_train_ind), len(built_test_ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1600, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_binned_full = cube_binned.reshape(cube_sub.shape[1], cube_sub.shape[2], num_of_bins)\n",
    "cube_binned_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 20) (200, 20)\n",
      "(480, 20) (120, 20)\n",
      "(808, 20) (202, 20)\n"
     ]
    }
   ],
   "source": [
    "cube_sky_train = cube_binned_full[sky_coords[sky_train_ind[:], 0], sky_coords[sky_train_ind[:], 1], :]\n",
    "cube_sky_test = cube_binned_full[sky_coords[sky_test_ind[:], 0], sky_coords[sky_test_ind[:], 1], :]\n",
    "print(cube_sky_train.shape, cube_sky_test.shape)\n",
    "\n",
    "cube_veg_train = cube_binned_full[veg_coords[veg_train_ind[:], 0], veg_coords[veg_train_ind[:], 1], :]\n",
    "cube_veg_test = cube_binned_full[veg_coords[veg_test_ind[:], 0], veg_coords[veg_test_ind[:], 1], :]\n",
    "print(cube_veg_train.shape, cube_veg_test.shape)\n",
    "\n",
    "cube_built_train = cube_binned_full[built_coords[built_train_ind[:], 0], built_coords[built_train_ind[:], 1], :]\n",
    "cube_built_test = cube_binned_full[built_coords[built_test_ind[:], 0], built_coords[built_test_ind[:], 1], :]\n",
    "print(cube_built_train.shape, cube_built_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate training and testing sets and create index arrays\n",
    "\n",
    "cube_train = np.concatenate((cube_sky_train, cube_veg_train, cube_built_train), axis=0)\n",
    "cube_train_labels = [0]*cube_sky_train.shape[0] + [1]*cube_veg_train.shape[0] + [2]*cube_built_train.shape[0]\n",
    "\n",
    "cube_test = np.concatenate((cube_sky_test, cube_veg_test, cube_built_test), axis=0)\n",
    "cube_test_labels = [0]*cube_sky_test.shape[0] + [1]*cube_veg_test.shape[0] + [2]*cube_built_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dTree = dt.fit(cube_train, cube_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = dTree.predict(cube_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
