{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperspectral Image Segmentation by Convolutional Neural Network \n",
    "\n",
    "### standardized spectra at full resolution with spatial dimension included\n",
    "\n",
    "### training on north facing image and testing on two south facing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- here are functions that generate a class that memory maps the raw data \n",
    "#    cube.  After executing this cell, the syntax is:\n",
    "#    fname = \"[path to data]/foo.raw\"\n",
    "#    cube = read_hyper(fname)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def read_header(hdrfile, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a Middleton header file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hdrfile : str\n",
    "        Name of header file.\n",
    "    verbose : bool, optional\n",
    "        If True, alert the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : dict\n",
    "        A dictionary continaing the number of rows, columns, and wavelengths\n",
    "        as well as an array of band centers.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- alert\n",
    "    if verbose:\n",
    "        print(\"reading and parsing {0}...\".format(hdrfile))\n",
    "\n",
    "    # -- open the file and read in the records\n",
    "    recs = [rec for rec in open(hdrfile)]\n",
    "\n",
    "    # -- parse for samples, lines, bands, and the start of the wavelengths\n",
    "    for irec, rec in enumerate(recs):\n",
    "        if 'samples' in rec:\n",
    "            samples = int(rec.split(\"=\")[1])\n",
    "        elif 'lines' in rec:\n",
    "            lines = int(rec.split(\"=\")[1])\n",
    "        elif 'bands' in rec:\n",
    "            bands = int(rec.split(\"=\")[1])\n",
    "        elif \"Wavelength\" in rec:\n",
    "            w0ind = irec+1\n",
    "\n",
    "    # -- parse for the wavelengths\n",
    "    waves = np.array([float(rec.split(\",\")[0]) for rec in \n",
    "                      recs[w0ind:w0ind+bands]])\n",
    "\n",
    "    # -- return a dictionary\n",
    "    return {\"nrow\":samples, \"ncol\":lines, \"nwav\":bands, \"waves\":waves}\n",
    "\n",
    "\n",
    "def read_raw(rawfile, shape, hyper=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a Middleton raw file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rawfile : str\n",
    "        The name of the raw file.\n",
    "    shape : tuple\n",
    "        The output shape of the data cube (nwav, nrow, ncol).\n",
    "    hyper : bool, optional\n",
    "        Set this flag to read a hyperspectral image.\n",
    "    verbose : bool, optional\n",
    "        Alert the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    memmap : memmap\n",
    "        A numpy memmap of the datacube.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- alert\n",
    "    if verbose:\n",
    "        print(\"reading {0}...\".format(rawfile))\n",
    "\n",
    "    # -- read either broadband or hyperspectral image\n",
    "    if hyper:\n",
    "        return np.memmap(rawfile, np.uint16, mode=\"r\") \\\n",
    "            .reshape(shape[2], shape[0], shape[1])[:, :, ::-1] \\\n",
    "            .transpose(1, 2, 0)\n",
    "    else:\n",
    "        return np.memmap(rawfile, np.uint8, mode=\"r\") \\\n",
    "            .reshape(shape[1], shape[2], shape[0])[:, :, ::-1]\n",
    "\n",
    "\n",
    "def read_hyper(fpath, fname=None, full=True):\n",
    "    \"\"\"\n",
    "    Read a full hyperspectral scan (raw and header file).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fpath : str\n",
    "        Either the full name+path of the raw file or the path of the raw file.\n",
    "        If the latter, fname must be supplied.\n",
    "    fname : str, optional\n",
    "        The name of the raw file (required if fpath is set to a path).\n",
    "    full : bool, optional\n",
    "        If True, output a class containing data and supplementary information.\n",
    "        If False, output only the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output or memmap : class or memmap\n",
    "        If full is True, a class containing data plus supplementary \n",
    "        information.  If full is False, a memmap array of the data.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- set up the file names\n",
    "    if fname is not None:\n",
    "        fpath = os.path.join(fpath, fname)\n",
    "\n",
    "    # -- read the header\n",
    "    hdr = read_header(fpath.replace(\"raw\", \"hdr\"))\n",
    "    sh  = (hdr[\"nwav\"], hdr[\"nrow\"], hdr[\"ncol\"])\n",
    "\n",
    "    # -- if desired, only output data cube\n",
    "    if not full:\n",
    "        return read_raw(fpath, sh, hyper=True)\n",
    "\n",
    "    # -- output full structure\n",
    "    class output():\n",
    "        def __init__(self, fpath):\n",
    "            self.filename = fpath\n",
    "            self.data     = read_raw(fpath, sh, hyper=True)\n",
    "            self.waves    = hdr[\"waves\"]\n",
    "            self.nwav     = sh[0]\n",
    "            self.nrow     = sh[1]\n",
    "            self.ncol     = sh[2]\n",
    "\n",
    "    return output(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_test_dictionary(labels, test, k):\n",
    "    import collections, numpy\n",
    "    \n",
    "    unique_test, counts_test = numpy.unique(labels[test[:,0], test[:,1]], return_counts=True)\n",
    "    counts_test_norm = (counts_test/test.shape[0])*100\n",
    "    test_dict = dict(zip(unique_test, counts_test))\n",
    "    test_dict_norm = dict(zip(unique_test, counts_test_norm))\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        if test_dict.get(i) is None: test_dict[i] = 0\n",
    "        if test_dict_norm.get(i) is None: test_dict_norm[i] = 0\n",
    "    \n",
    "    return test_dict, test_dict_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_test_dataframe(sky_dict,\n",
    "                          clouds_dict,\n",
    "                          veg_dict,\n",
    "                          wtr_dict,\n",
    "                          blt_dict,\n",
    "                          windows_dict,\n",
    "                          rds_dict,\n",
    "                          cars_dict,\n",
    "                          mtl_dict\n",
    "                         ):\n",
    "    import pandas as pd\n",
    "    \n",
    "    pixel_names = ['sky', 'clouds', 'vegetation', 'water', 'built',\n",
    "                  'windows', 'roads', 'cars', 'metal']\n",
    "    df_test = pd.DataFrame([sky_dict,\n",
    "                            clouds_dict,\n",
    "                            veg_dict,\n",
    "                            wtr_dict,\n",
    "                            blt_dict,\n",
    "                            windows_dict,\n",
    "                            rds_dict,\n",
    "                            cars_dict,\n",
    "                            mtl_dict], index=pixel_names)\n",
    "    df_test = df_test.transpose()\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(df_test, norm=True):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    cm = np.array([df_test['sky'].values,\n",
    "                   df_test['clouds'].values,\n",
    "                   df_test['vegetation'].values,\n",
    "                   df_test['water'].values,\n",
    "                   df_test['built'].values,\n",
    "                   df_test['windows'].values,\n",
    "                   df_test['roads'].values,\n",
    "                   df_test['cars'].values,\n",
    "                   df_test['metal'].values])\n",
    "    classes = ['sky', 'clouds', 'vegetation', 'water', 'built', 'windows', 'roads', \n",
    "              'cars', 'metal']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    if norm:\n",
    "        title='Normalized Confusion Matrix'\n",
    "        fmt='.2f'\n",
    "    else:\n",
    "        title='Confusion Matrix'\n",
    "        fmt='d'\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "          yticks=np.arange(cm.shape[0]),\n",
    "          xticklabels=np.arange(0,cm.shape[1]).astype(str), \n",
    "          yticklabels=classes,\n",
    "          title=title,\n",
    "          ylabel='True Label',\n",
    "          xlabel='Predicted Label')\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "    #        rotation_mode=\"anchor\")\n",
    "    thresh = cm.max()/2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i,j], fmt),\n",
    "                   ha=\"center\", va=\"center\",\n",
    "                   color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_result(df_Test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    df_test = df_Test.transpose()\n",
    "    ax = df_test.plot.bar(rot=0, stacked=True, colormap='tab20b')\n",
    "                          #color=['tab:blue', 'tab:green', 'tab:gray'])\n",
    "    plt.xlabel('Actual Class')\n",
    "    plt.ylabel('%of Test Pixels')\n",
    "    plt.title('Error in Kmeans Prediction')\n",
    "    plt.legend(bbox_to_anchor=(1,1), loc=2, borderaxespad=1.0, prop={'size':11})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_from_string(text):\n",
    "    \n",
    "    items = text.strip(\"\\n\").split(\" \")\n",
    "    rind = int(items[0])\n",
    "    cind = int(items[1])\n",
    "    \n",
    "    return rind, cind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords(row, col):\n",
    "    return np.array(list(np.ndindex((row, col)))).reshape(row, col, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Classes:\n",
    "1. Sky\n",
    "2. Clouds\n",
    "3. Water\n",
    "4. Vegetation\n",
    "5. Buildings (concrete structures)\n",
    "6. Windows\n",
    "7. Roads\n",
    "8. Cars\n",
    "9. Metal Structures\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Trained on North Facing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_north = \"../../image_files/scan1_slow_roof_VNIR.raw\"\n",
    "cube_north = read_hyper(fname_north)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_sub_north = cube_north.data[:, :, :].astype(float)\n",
    "print(cube_sub_north.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_reshaped_north = cube_sub_north.transpose(1, 2, 0).reshape((cube_sub_north.shape[1] * cube_sub_north.shape[2]), cube_sub_north.shape[0])\n",
    "print(cube_reshaped_north.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_norm_north = (cube_reshaped_north - cube_reshaped_north.min()) / (cube_reshaped_north.max() - cube_reshaped_north.min())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "red_ind_n = (np.abs(cube_north.waves - 650.0)).argmin()\n",
    "green_ind_n = (np.abs(cube_north.waves - 550.0)).argmin()\n",
    "blue_ind_n = (np.abs(cube_north.waves - 450.0)).argmin()\n",
    "\n",
    "cube_reshaped_north2 = cube_norm_north.reshape(cube_sub_north.shape[1], cube_sub_north.shape[2], cube_sub_north.shape[0])\n",
    "cube_scene_north = cube_reshaped_north2[:, :, [red_ind_n, green_ind_n, blue_ind_n]]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('North Facing RGB Image')\n",
    "ax.imshow(cube_scene_north, aspect=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbn = cube_reshaped_north2[:, :, [red_ind_n, green_ind_n, blue_ind_n]].copy()\n",
    "rgbn /= rgbn.mean((0, 1), keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.title('North Facing corrected RGB Image')\n",
    "ax.imshow(rgbn.clip(0, 1)**0.5, aspect=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_standard_north = (cube_reshaped_north - cube_reshaped_north.mean(1, keepdims=True)) / cube_reshaped_north.std(1, keepdims=True)\n",
    "cube_reshaped_north = cube_standard_north"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cube_north.waves))\n",
    "print(min(cube_north.waves), max(cube_north.waves))\n",
    "print(cube_reshaped_north.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create position array and normalize\n",
    "\n",
    "xycoordsn = coords(cube_sub_north.shape[1], cube_sub_north.shape[2])\n",
    "xycoordsn = xycoordsn/xycoordsn.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append row, col position matrix to spectral data\n",
    "\n",
    "cube_tempn = cube_reshaped_north.reshape(cube_sub_north.shape[1], cube_sub_north.shape[2], cube_reshaped_north.shape[1])\n",
    "cube_specxyn = np.append(cube_tempn, xycoordsn, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape spectral and spatial cube for clustering\n",
    "cube_specxyn_2d = cube_specxyn.reshape((cube_specxyn.shape[0] * cube_specxyn.shape[1]), cube_specxyn.shape[2])\n",
    "print(cube_specxyn_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading manually classified set for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read manually selected coordinates files\n",
    "\n",
    "#sky coordinates\n",
    "sky_filen = open(\"../manual_classified_pixels/1_sky_coordinates_north.txt\", \"r\")\n",
    "sky_coordsn = sky_filen.readlines()\n",
    "sky_filen.close()\n",
    "sky_coordsn = np.array([point_from_string(line) for line in sky_coordsn])\n",
    "print(\"sky:        \", sky_coordsn.shape)\n",
    "\n",
    "#clouds coordinates\n",
    "clouds_filen = open(\"../manual_classified_pixels/2_clouds_coordinates_north.txt\", \"r\")\n",
    "clouds_coordsn = clouds_filen.readlines()\n",
    "clouds_filen.close()\n",
    "clouds_coordsn = np.array([point_from_string(line) for line in clouds_coordsn])\n",
    "print(\"clouds:     \", clouds_coordsn.shape)\n",
    "\n",
    "#vegetation coordinates\n",
    "veg_filen = open(\"../manual_classified_pixels/3_vegetation_coordinates_north.txt\", \"r\")\n",
    "veg_coordsn = veg_filen.readlines()\n",
    "veg_filen.close()\n",
    "veg_coordsn = np.array([point_from_string(line) for line in veg_coordsn])\n",
    "print(\"vegetation: \", veg_coordsn.shape)\n",
    "\n",
    "#water coordinates\n",
    "wtr_filen = open(\"../manual_classified_pixels/4_water_coordinates_north.txt\", \"r\")\n",
    "wtr_coordsn = wtr_filen.readlines()\n",
    "wtr_filen.close()\n",
    "wtr_coordsn = np.array([point_from_string(line) for line in wtr_coordsn])\n",
    "print(\"water:      \", wtr_coordsn.shape)\n",
    "\n",
    "#buildings coordinates\n",
    "blt_filen = open(\"../manual_classified_pixels/5_buildings_coordinates_north.txt\", \"r\")\n",
    "blt_coordsn = blt_filen.readlines()\n",
    "blt_filen.close()\n",
    "blt_coordsn = np.array([point_from_string(line) for line in blt_coordsn])\n",
    "print(\"buildings:  \", blt_coordsn.shape)\n",
    "\n",
    "#windows coordinates\n",
    "windows_filen = open(\"../manual_classified_pixels/6_windows_coordinates_north.txt\", \"r\")\n",
    "windows_coordsn = windows_filen.readlines()\n",
    "windows_filen.close()\n",
    "windows_coordsn = np.array([point_from_string(line) for line in windows_coordsn])\n",
    "print(\"windows:    \", windows_coordsn.shape)\n",
    "\n",
    "#roads coordinates\n",
    "rds_filen = open(\"../manual_classified_pixels/7_roads_coordinates_north.txt\", \"r\")\n",
    "rds_coordsn = rds_filen.readlines()\n",
    "rds_filen.close()\n",
    "rds_coordsn = np.array([point_from_string(line) for line in rds_coordsn])\n",
    "print(\"road:       \", rds_coordsn.shape)\n",
    "\n",
    "#cars coordinates\n",
    "cars_filen = open(\"../manual_classified_pixels/8_cars_coordinates_north.txt\", \"r\")\n",
    "cars_coordsn = cars_filen.readlines()\n",
    "cars_filen.close()\n",
    "cars_coordsn = np.array([point_from_string(line) for line in cars_coordsn])\n",
    "print(\"cars:       \", cars_coordsn.shape)\n",
    "\n",
    "#metal coordinates\n",
    "mtl_filen = open(\"../manual_classified_pixels/9_metal_coordinates_north.txt\", \"r\")\n",
    "mtl_coordsn = mtl_filen.readlines()\n",
    "mtl_filen.close()\n",
    "mtl_coordsn = np.array([point_from_string(line) for line in mtl_coordsn])\n",
    "print(\"metal:      \", mtl_coordsn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split classified pixels into 80% training and 20% testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# sky coordinates\n",
    "sky_indn = np.arange(sky_coordsn.shape[0])\n",
    "random.Random(3).shuffle(sky_indn)\n",
    "lim_ind = int(len(sky_indn)*0.8)\n",
    "sky_train_indn = sky_indn[:lim_ind]\n",
    "sky_test_indn = sky_indn[lim_ind:]\n",
    "print(\"sky %d %d\" % (len(sky_train_indn), len(sky_test_indn)))\n",
    "\n",
    "# clouds coordinates\n",
    "clouds_indn = np.arange(clouds_coordsn.shape[0])\n",
    "random.Random(3).shuffle(clouds_indn)\n",
    "lim_ind = int(len(clouds_indn)*0.8)\n",
    "clouds_train_indn = clouds_indn[:lim_ind]\n",
    "clouds_test_indn = clouds_indn[lim_ind:]\n",
    "print(\"clouds %d %d\" % (len(clouds_train_indn), len(clouds_test_indn)))\n",
    "\n",
    "# vegetation coordinates\n",
    "veg_indn = np.arange(veg_coordsn.shape[0])\n",
    "random.Random(3).shuffle(veg_indn)\n",
    "lim_ind = int(len(veg_indn)*0.8)\n",
    "veg_train_indn = veg_indn[:lim_ind]\n",
    "veg_test_indn = veg_indn[lim_ind:]\n",
    "print(\"vegetation %d %d\" % (len(veg_train_indn), len(veg_test_indn)))\n",
    "\n",
    "# water coordinates\n",
    "wtr_indn = np.arange(wtr_coordsn.shape[0])\n",
    "random.Random(3).shuffle(wtr_indn)\n",
    "lim_ind = int(len(wtr_indn)*0.8)\n",
    "wtr_train_indn = wtr_ind[:lim_ind]\n",
    "wtr_test_indn = wtr_ind[lim_ind:]\n",
    "print(\"water %d %d\" % (len(wtr_train_indn), len(wtr_test_indn)))\n",
    "\n",
    "# built coordinates\n",
    "blt_indn = np.arange(blt_coordsn.shape[0])\n",
    "random.Random(3).shuffle(blt_indn)\n",
    "lim_ind = int(len(blt_indn)*0.8)\n",
    "blt_train_indn = blt_indn[:lim_ind]\n",
    "blt_test_indn = blt_indn[lim_ind:]\n",
    "print(\"built %d %d\" % (len(blt_train_indn), len(blt_test_indn)))\n",
    "\n",
    "# windows coordinates\n",
    "windows_indn = np.arange(windows_coordsn.shape[0])\n",
    "random.Random(3).shuffle(windows_indn)\n",
    "lim_ind = int(len(windows_indn)*0.8)\n",
    "windows_train_indn = windows_indn[:lim_ind]\n",
    "windows_test_indn = windows_indn[lim_ind:]\n",
    "print(\"windows %d %d\" % (len(windows_train_indn), len(windows_test_indn)))\n",
    "\n",
    "# roads coordinates\n",
    "rds_indn = np.arange(rds_coordsn.shape[0])\n",
    "random.Random(3).shuffle(rds_indn)\n",
    "lim_ind = int(len(rds_indn)*0.8)\n",
    "rds_train_indn = rds_indn[:lim_ind]\n",
    "rds_test_indn = rds_indn[lim_ind:]\n",
    "print(\"roads %d %d\" % (len(rds_train_indn), len(rds_test_indn)))\n",
    "\n",
    "# cars coordinates\n",
    "cars_indn = np.arange(cars_coordsn.shape[0])\n",
    "random.Random(3).shuffle(cars_indn)\n",
    "lim_ind = int(len(cars_indn)*0.8)\n",
    "cars_train_indn = cars_indn[:lim_ind]\n",
    "cars_test_indn = cars_indn[lim_ind:]\n",
    "print(\"cars %d %d\" % (len(cars_train_indn), len(cars_test_indn)))\n",
    "\n",
    "# metal coordinates\n",
    "mtl_indn = np.arange(mtl_coordsn.shape[0])\n",
    "random.Random(3).shuffle(mtl_indn)\n",
    "lim_ind = int(len(mtl_indn)*0.8)\n",
    "mtl_train_indn = mtl_indn[:lim_ind]\n",
    "mtl_test_indn = mtl_indn[lim_ind:]\n",
    "print(\"metal %d %d\" % (len(mtl_train_indn), len(mtl_test_indn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_sky_trainn = cube_specxyn[sky_coordsn[sky_train_indn[:], 0], sky_coordsn[sky_train_indn[:], 1], :]\n",
    "cube_sky_testn = cube_specxyn[sky_coordsn[sky_test_indn[:], 0], sky_coordsn[sky_test_indn[:], 1], :]\n",
    "print(\"sky \", cube_sky_trainn.shape, cube_sky_testn.shape)\n",
    "\n",
    "cube_clouds_trainn = cube_specxyn[clouds_coordsn[clouds_train_indn[:], 0], clouds_coordsn[clouds_train_indn[:], 1], :]\n",
    "cube_clouds_testn = cube_specxyn[clouds_coordsn[clouds_test_indn[:], 0], clouds_coordsn[clouds_test_indn[:], 1], :]\n",
    "print(\"clouds \", cube_clouds_trainn.shape, cube_clouds_testn.shape)\n",
    "\n",
    "cube_veg_trainn = cube_specxyn[veg_coordsn[veg_train_indn[:], 0], veg_coordsn[veg_train_indn[:], 1], :]\n",
    "cube_veg_testn = cube_specxyn[veg_coordsn[veg_test_indn[:], 0], veg_coordsn[veg_test_indn[:], 1], :]\n",
    "print(\"vegetation \", cube_veg_trainn.shape, cube_veg_testn.shape)\n",
    "\n",
    "cube_wtr_trainn = cube_specxyn[wtr_coordsn[wtr_train_indn[:], 0], wtr_coordsn[wtr_train_indn[:], 1], :]\n",
    "cube_wtr_testn = cube_specxyn[wtr_coordsn[wtr_test_indn[:], 0], wtr_coordsn[wtr_test_indn[:], 1], :]\n",
    "print(\"water \", cube_wtr_trainn.shape, cube_wtr_testn.shape)\n",
    "\n",
    "cube_blt_trainn = cube_specxyn[blt_coordsn[blt_train_indn[:], 0], blt_coordsn[blt_train_indn[:], 1], :]\n",
    "cube_blt_testn = cube_specxyn[blt_coordsn[blt_test_indn[:], 0], blt_coordsn[blt_test_indn[:], 1], :]\n",
    "print(\"built \", cube_blt_trainn.shape, cube_blt_testn.shape)\n",
    "\n",
    "cube_windows_trainn = cube_specxyn[windows_coordsn[windows_train_indn[:], 0], windows_coordsn[windows_train_indn[:], 1], :]\n",
    "cube_windows_testn = cube_specxyn[windows_coordsn[windows_test_indn[:], 0], windows_coordsn[windows_test_indn[:], 1], :]\n",
    "print(\"windows \", cube_windows_trainn.shape, cube_windows_testn.shape)\n",
    "\n",
    "cube_rds_trainn = cube_specxyn[rds_coordsn[rds_train_indn[:], 0], rds_coordsn[rds_train_indn[:], 1], :]\n",
    "cube_rds_testn = cube_specxyn[rds_coordsn[rds_test_indn[:], 0], rds_coordsn[rds_test_indn[:], 1], :]\n",
    "print(\"roads \", cube_rds_trainn.shape, cube_rds_testn.shape)\n",
    "\n",
    "cube_cars_trainn = cube_specxyn[cars_coordsn[cars_train_indn[:], 0], cars_coordsn[cars_train_indn[:], 1], :]\n",
    "cube_cars_testn = cube_specxyn[cars_coordsn[cars_test_indn[:], 0], cars_coordsn[cars_test_indn[:], 1], :]\n",
    "print(\"cars \", cube_cars_trainn.shape, cube_cars_testn.shape)\n",
    "\n",
    "cube_mtl_trainn = cube_specxyn[mtl_coordsn[mtl_train_indn[:], 0], mtl_coordsn[mtl_train_indn[:], 1], :]\n",
    "cube_mtl_testn = cube_specxyn[mtl_coordsn[mtl_test_indn[:], 0], mtl_coordsn[mtl_test_indn[:], 1], :]\n",
    "print(\"metal \", cube_mtl_trainn.shape, cube_mtl_testn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate training and testing sets and create index arrays\n",
    "\n",
    "cube_trainn = np.concatenate((cube_sky_trainn, cube_clouds_trainn, cube_veg_trainn, cube_blt_trainn, cube_wtr_trainn,\n",
    "                            cube_windows_trainn, cube_rds_trainn, cube_cars_trainn, cube_mtl_trainn), axis=0)\n",
    "cube_train_labelsn = [0]*cube_sky_trainn.shape[0] + [1]*cube_clouds_trainn.shape[0] \\\n",
    "                    + [2]*cube_veg_trainn.shape[0] + [3]*cube_wtr_trainn.shape[0] + [4]*cube_blt_trainn.shape[0] \\\n",
    "                    + [5]*cube_windows_trainn.shape[0] + [6]*cube_rds_trainn.shape[0] \\\n",
    "                    + [7]*cube_cars_trainn.shape[0] + [8]*cube_mtl_trainn.shape[0]\n",
    "\n",
    "print(cube_trainn.shape)\n",
    "\n",
    "cube_testn = np.concatenate((cube_sky_testn, cube_clouds_testn, cube_veg_testn, cube_blt_testn, cube_wtr_testn,\n",
    "                            cube_windows_testn, cube_rds_testn, cube_cars_testn, cube_mtl_testn), axis=0)\n",
    "cube_test_labelsn = [0]*cube_sky_testn.shape[0] + [1]*cube_clouds_testn.shape[0] \\\n",
    "                    + [2]*cube_veg_testn.shape[0] + [3]*cube_wtr_testn.shape[0] + [4]*cube_blt_testn.shape[0] \\\n",
    "                    + [5]*cube_windows_testn.shape[0] + [6]*cube_rds_testn.shape[0] \\\n",
    "                    + [7]*cube_cars_testn.shape[0] + [8]*cube_mtl_testn.shape[0]\n",
    "\n",
    "print(cube_testn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "cnnn = keras.Sequential([keras.layers.Conv1D(32, kernel_size=(5), padding=\"same\", \n",
    "                                            activation=\"relu\", input_shape=(cube_specxyn.shape[2], 1)),\n",
    "                       keras.layers.MaxPooling1D((2), strides=2),\n",
    "                        keras.layers.Conv1D(64, kernel_size=(5), padding=\"same\", activation=\"relu\"),\n",
    "                        keras.layers.MaxPooling1D((2), strides=2),\n",
    "                        keras.layers.Flatten(),\n",
    "                        keras.layers.Dense(1024, activation=\"relu\"),\n",
    "                        keras.layers.Dense(10, activation=\"softmax\")])\n",
    "\n",
    "cnnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",\n",
    "           metrics=[\"accuracy\"])\n",
    "\n",
    "cube_trainn2 = cube_trainn.reshape(cube_trainn.shape[0], cube_trainn.shape[1], 1)\n",
    "cube_testn2 = cube_testn.reshape(cube_testn.shape[0], cube_testn.shape[1], 1)\n",
    "\n",
    "CNNmodeln = cnnn.fit(cube_trainn2, cube_train_labelsn, epochs=50, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history of loss\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(12, 10))\n",
    "ax1.plot(CNNmodeln.history['loss'])\n",
    "ax1.plot(CNNmodeln.history['val_loss'])\n",
    "ax1.set_title('CNN Model Loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.locator_params(nbins=13, axis='x')\n",
    "ax1.legend(['train', 'test'], loc='center right')\n",
    "ax2.plot(CNNmodeln.history['accuracy'])\n",
    "ax2.plot(CNNmodeln.history['val_accuracy'])\n",
    "ax2.set_title('CNN Model Accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.locator_params(nbins=12, axis='x')\n",
    "ax2.legend(['train', 'test'], loc='center right')\n",
    "ax3.plot(CNNmodeln.history['loss'])\n",
    "ax3.plot(CNNmodeln.history['val_loss'])\n",
    "ax3.set_ylabel('log(loss)')\n",
    "ax3.set_xlabel('epoch')\n",
    "ax3.locator_params(nbins=13, axis='x')\n",
    "ax3.legend(['train', 'test'], loc='center right')\n",
    "ax3.set_yscale('log')\n",
    "ax4.plot(CNNmodeln.history['accuracy'])\n",
    "ax4.plot(CNNmodeln.history['val_accuracy'])\n",
    "ax4.set_ylabel('log(accuracy)')\n",
    "ax4.set_xlabel('epoch')\n",
    "ax4.locator_params(nbins=12, axis='x')\n",
    "ax4.legend(['train', 'test'], loc='center right')\n",
    "ax4.set_yscale('log')\n",
    "plt.show\n",
    "f.savefig(\"./plots/CNN_spatial_train_north_1_north_CNN_loss_accuracy_vs_epoch.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "cnnn = keras.Sequential([keras.layers.Conv1D(32, kernel_size=(5), padding=\"same\", \n",
    "                                            activation=\"relu\", input_shape=(cube_specxyn.shape[2], 1)),\n",
    "                       keras.layers.MaxPooling1D((2), strides=2),\n",
    "                        keras.layers.Conv1D(64, kernel_size=(5), padding=\"same\", activation=\"relu\"),\n",
    "                        keras.layers.MaxPooling1D((2), strides=2),\n",
    "                        keras.layers.Flatten(),\n",
    "                        keras.layers.Dense(1024, activation=\"relu\"),\n",
    "                        keras.layers.Dense(10, activation=\"softmax\")])\n",
    "\n",
    "cnnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",\n",
    "           metrics=[\"accuracy\"])\n",
    "\n",
    "cube_trainn2 = cube_trainn.reshape(cube_trainn.shape[0], cube_trainn.shape[1], 1)\n",
    "cube_testn2 = cube_testn.reshape(cube_testn.shape[0], cube_testn.shape[1], 1)\n",
    "\n",
    "CNNmodeln = cnnn.fit(cube_trainn2, cube_train_labelsn, epochs=20, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy on training and testing sets\n",
    "\n",
    "train_loss, train_acc = cnnn.evaluate(cube_trainn2, cube_train_labelsn)\n",
    "test_loss, test_acc = cnnn.evaluate(cube_testn2, cube_test_labelsn)\n",
    "\n",
    "print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict pixel classification on north facing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "cube_specxyn_2d_1 = cube_specxyn_2d.reshape(cube_specxyn_2d.shape[0], cube_specxyn_2d.shape[1], 1)\n",
    "\n",
    "predictCuben = cnnn.predict_classes(cube_specxyn_2d_1)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictCube_reshapen = predictCuben.reshape(cube_sub_north.shape[1], cube_sub_north.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as ListedColorMap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "cmap = {0:[0,0.32549,0.62353,1], 1:[0.93333,0.9098,0.77255,1], 2:[0,0.61961,0.45098,1],  3:[0.33725,0.70588,0.91373,1],\n",
    "        4:[0,0,0,1], 5:[1,0.82353,0,1], 6:[0.90196,0.62353,0,1], 7:[0.83529,0.36863,0,1],\n",
    "        8:[0.8,0.47451,0.65490,1]}\n",
    "labels = {0:'sky', 1:'clouds', 2:'vegetation', 3:'water', 4:'built',\n",
    "          5:'windows', 6:'roads', 7:'cars', 8:'metal'}\n",
    "arrayShow = np.array([[cmap[i] for i in j] for j in predictCube_reshapen])\n",
    "patches = [mpatches.Patch(color=cmap[i], label=labels[i]) for i in cmap]\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "ax.tick_params(labelsize=10)\n",
    "ax.imshow(arrayShow, aspect=0.4)\n",
    "lgd = ax.legend(handles=patches, bbox_to_anchor=(1,0.75), loc='upper left', borderaxespad=1.0, prop={'size':10}, ncol=1)\n",
    "plt.show()\n",
    "fig.savefig(\"./plots/CNN_spatial_train_north_2_north_predict_map.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_by_row_north = np.zeros(cube_sub_north.shape[1])\n",
    "for row in range(0, cube_sub_north.shape[1]):\n",
    "    veg_by_row_north[row] = np.count_nonzero(predictCube_reshapen[row,:] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as ListedColorMap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "cmap = {0:[0,0.32549,0.62353,1], 1:[0.93333,0.9098,0.77255,1], 2:[0,0.61961,0.45098,1],  3:[0.33725,0.70588,0.91373,1],\n",
    "        4:[0,0,0,1], 5:[1,0.82353,0,1], 6:[0.90196,0.62353,0,1], 7:[0.83529,0.36863,0,1],\n",
    "        8:[0.8,0.47451,0.65490,1]}\n",
    "labels = {0:'sky', 1:'clouds', 2:'vegetation', 3:'water', 4:'built',\n",
    "          5:'windows', 6:'roads', 7:'cars', 8:'metal'}\n",
    "arrayShow = np.array([[cmap[i] for i in j] for j in predictCube_reshapen])\n",
    "patches = [mpatches.Patch(color=cmap[i], label=labels[i]) for i in cmap]\n",
    "#fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "fig = plt.figure(1, figsize=(30,10))\n",
    "axImage = plt.axes([0.1,0.1,0.85,0.95])\n",
    "axHist = plt.axes([0.85,0.1,0.2,0.95])\n",
    "axHist.yaxis.set_major_formatter(NullFormatter())\n",
    "axImage.tick_params(labelsize=20)\n",
    "axHist.tick_params(labelsize=20)\n",
    "axImage.imshow(arrayShow, aspect=0.5)\n",
    "axHist.plot(veg_by_row_north, np.arange(0,cube_sub.shape[1]), color=[0.0,0.33,0.62])\n",
    "axHist.fill_between(veg_by_row_north, np.arange(0,cube_sub_north.shape[1]), cube_sub_north.shape[1], facecolor=[0.0,0.33,0.62])\n",
    "axHist.set_ylim(cube_sub_north.shape[1], 0)\n",
    "axHist.set(title='Vegetation Pixels by Row')\n",
    "axHist.title.set_fontsize(25)\n",
    "lgd = axImage.legend(handles=patches, bbox_to_anchor=(0,0.5), loc=2, borderaxespad=-13.0, prop={'size':20}, ncol=1)\n",
    "plt.show()\n",
    "#fig.savefig(\"./output/plots/19_kmeans_clustering_of_veg_00108.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean spectra for testing set separately\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize=(12, 10))\n",
    "plt.suptitle('Mean Standardized Spectra of Classified Pixels (north) vs Testing Pixels (north) vs Training Pixels (north)')\n",
    "ax1.plot(cube_north.waves, cube_sky_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax1.plot(cube_north.waves, cube_sky_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax1.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 0)[0]].mean(0), color=[0,0.32549,0.62353])\n",
    "ax1.set_title(\"Sky\")\n",
    "ax1.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax2.plot(cube_north.waves, cube_clouds_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax2.plot(cube_north.waves, cube_clouds_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax2.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 1)[0]].mean(0), color=[0.93333,0.9098,0.77255])\n",
    "ax2.set_title(\"Clouds\")\n",
    "ax2.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax3.plot(cube_north.waves, cube_veg_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax3.plot(cube_north.waves, cube_veg_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax3.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 2)[0]].mean(0), color=[0,0.61961,0.45098])\n",
    "ax3.set_title(\"Vegetation\")\n",
    "ax3.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax4.plot(cube_north.waves, cube_wtr_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax4.plot(cube_north.waves, cube_wtr_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax4.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 3)[0]].mean(0), color=[0.33725,0.70588,0.91373])\n",
    "ax4.set_title(\"Water\")\n",
    "ax4.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax5.plot(cube_north.waves, cube_blt_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax5.plot(cube_north.waves, cube_blt_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax5.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 4)[0]].mean(0), color=[0,0,0])\n",
    "ax5.set_title(\"Built\")\n",
    "ax5.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax6.plot(cube_north.waves, cube_windows_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax6.plot(cube_north.waves, cube_windows_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax6.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 5)[0]].mean(0), color=[1,0.82353,0])\n",
    "ax6.set_title(\"Windows\")\n",
    "ax6.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax7.plot(cube_north.waves, cube_rds_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax7.plot(cube_north.waves, cube_rds_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax7.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 6)[0]].mean(0), color=[0.90196,0.62353,0])\n",
    "ax7.set_title(\"Roads\")\n",
    "ax7.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax8.plot(cube_north.waves, cube_cars_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax8.plot(cube_north.waves, cube_cars_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax8.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 7)[0]].mean(0), color=[0.83529,0.36863,0])\n",
    "ax8.set_title(\"Cars\")\n",
    "ax8.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "ax9.plot(cube_north.waves, cube_mtl_trainn[:,:-2].mean(0), color=[0.170,0,0,0.75], lw=1, ls=\"dashed\")\n",
    "ax9.plot(cube_north.waves, cube_mtl_testn[:,:-2].mean(0), color=[0.170,0,0,0.5], lw=1, ls=\"dotted\")\n",
    "ax9.plot(cube_north.waves, cube_reshaped_north[np.where(predictCuben == 8)[0]].mean(0), color=[0.8,0.47451,0.65490])\n",
    "ax9.set_title(\"Metal\")\n",
    "ax9.legend(['train', 'test', 'predict'], loc='upper right')\n",
    "plt.show()\n",
    "f.savefig(\"./plots/CNN_spatial_train_north_3_north_mean_spectra_train_test_predict_3x3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics (north facing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsn_pred_sky = predictCube_reshapen[sky_coordsn[:,0], sky_coordsn[:,1]]\n",
    "labelsn_pred_clouds = predictCube_reshapen[clouds_coordsn[:,0], clouds_coordsn[:,1]]\n",
    "labelsn_pred_veg = predictCube_reshapen[veg_coordsn[:,0], veg_coordsn[:,1]]\n",
    "labelsn_pred_wtr = predictCube_reshapen[wtr_coordsn[:,0], wtr_coordsn[:,1]]\n",
    "labelsn_pred_blt = predictCube_reshapen[blt_coordsn[:,0], blt_coordsn[:,1]]\n",
    "labelsn_pred_windows = predictCube_reshapen[windows_coordsn[:,0], windows_coordsn[:,1]]\n",
    "labelsn_pred_rds = predictCube_reshapen[rds_coordsn[:,0], rds_coordsn[:,1]]\n",
    "labelsn_pred_cars = predictCube_reshapen[cars_coordsn[:,0], cars_coordsn[:,1]]\n",
    "labelsn_pred_mtl = predictCube_reshapen[mtl_coordsn[:,0], mtl_coordsn[:,1]]\n",
    "\n",
    "labelsn_pred = np.concatenate((labelsn_pred_sky, labelsn_pred_clouds, labelsn_pred_veg, labelsn_pred_wtr, \n",
    "                             labelsn_pred_blt, labelsn_pred_windows, labelsn_pred_rds, labelsn_pred_cars, labelsn_pred_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsn_true_sky = np.full((sky_coordsn.shape[0]), 0)\n",
    "labelsn_true_clouds = np.full((clouds_coordsn.shape[0]), 1)\n",
    "labelsn_true_veg = np.full((veg_coordsn.shape[0]), 2)\n",
    "labelsn_true_wtr = np.full((wtr_coordsn.shape[0]), 3)\n",
    "labelsn_true_blt = np.full((blt_coordsn.shape[0]), 4)\n",
    "labelsn_true_windows = np.full((windows_coordsn.shape[0]), 5)\n",
    "labelsn_true_rds = np.full((rds_coordsn.shape[0]), 6)\n",
    "labelsn_true_cars = np.full((cars_coordsn.shape[0]), 7)\n",
    "labelsn_true_mtl = np.full((mtl_coordsn.shape[0]), 8)\n",
    "\n",
    "labelsn_true = np.concatenate((labelsn_true_sky, labelsn_true_clouds, labelsn_true_veg, labelsn_true_wtr, \n",
    "                             labelsn_true_blt, labelsn_true_windows, labelsn_true_rds, labelsn_true_cars, labelsn_true_mtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labelsn_pred.shape)\n",
    "print(labelsn_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(labelsn_true, labelsn_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy Score\")\n",
    "print(metrics.accuracy_score(labelsn_true, labelsn_pred))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(labelsn_true, labelsn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./metrics/CNN_spatial_train_north_test_north_metrics.txt\", \"w\")\n",
    "f.write(\"Confusion Matrix\")\n",
    "f.write('\\n')\n",
    "f.write(str(metrics.confusion_matrix(labelsn_true, labelsn_pred)))\n",
    "f.write('\\n')\n",
    "f.write('\\n')\n",
    "f.write(\"Accuracy Score\")\n",
    "f.write('\\n')\n",
    "f.write(str(metrics.accuracy_score(labelsn_true, labelsn_pred)))\n",
    "target_names = ['sky', 'clouds', 'vegetation', 'water', 'built', 'windows', 'roads', 'cars', 'metal']\n",
    "f.write('\\n')\n",
    "f.write('\\n')\n",
    "f.write(\"Classification Report\")\n",
    "f.write('\\n')\n",
    "f.write(metrics.classification_report(labelsn_true, labelsn_pred, target_names=target_names))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_dictn, sky_dict_normn = kmeans_test_dictionary(predictCube_reshapen, sky_coordsn, 9)\n",
    "clouds_dictn, cloud_dict_normn = kmeans_test_dictionary(predictCube_reshapen, clouds_coordsn, 9)\n",
    "veg_dictn, veg_dict_normn = kmeans_test_dictionary(predictCube_reshapen, veg_coordsn, 9)\n",
    "wtr_dictn, wtr_dict_normn = kmeans_test_dictionary(predictCube_reshapen, wtr_coordsn, 9)\n",
    "blt_dictn, blt_dict_normn = kmeans_test_dictionary(predictCube_reshapen, blt_coordsn, 9)\n",
    "windows_dictn, windows_dict_normn = kmeans_test_dictionary(predictCube_reshapen, windows_coordsn, 9)\n",
    "rds_dictn, rds_dict_normn = kmeans_test_dictionary(predictCube_reshapen, rds_coordsn, 9)\n",
    "cars_dictn, cars_dict_normn = kmeans_test_dictionary(predictCube_reshapen, cars_coordsn, 9)\n",
    "mtl_dictn, mtl_dict_normn = kmeans_test_dictionary(predictCube_reshapen, mtl_coordsn, 9)\n",
    "\n",
    "df_testn = kmeans_test_dataframe(sky_dictn, clouds_dictn, veg_dictn, wtr_dictn,\n",
    "                                blt_dictn, windows_dictn, rds_dictn, cars_dictn, mtl_dictn)\n",
    "print(df_testn.transpose())\n",
    "df_test_normn = kmeans_test_dataframe(sky_dictn, clouds_dictn, veg_dictn, wtr_dictn,\n",
    "                                     blt_dictn, windows_dictn, rds_dictn, cars_dictn, mtl_dictn)\n",
    "#print(\"\")\n",
    "#print(df_test_normn.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_testn, norm=False)\n",
    "#plot_confusion_matrix(df_test_normn, norm=True)\n",
    "plot_test_result(df_test_normn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
